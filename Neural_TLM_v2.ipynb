{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_TLM_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smallcats/TopicalLanguageModels/blob/master/Neural_TLM_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTWYvbXC68CH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Flatten, Lambda, Concatenate, Reshape, Dot, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP5TY8t97Gk1",
        "colab_type": "code",
        "outputId": "b9f496ee-597d-4972-9829-e17d7b92e796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = stopwords.words('english')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4z-eaM57HjV",
        "colab_type": "code",
        "outputId": "6f34c5b7-1c56-4e02-9bce-a8e550454f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "nltk.corpus.gutenberg.fileids()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq8Cw9Ct7MyJ",
        "colab_type": "code",
        "outputId": "13364e7c-b3bb-4349-ad3b-c2f828802406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "thurs = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
        "leaves = nltk.corpus.gutenberg.raw('whitman-leaves.txt')\n",
        "len(thurs), len(leaves)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(320525, 711215)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRgEYnfL8BYe",
        "colab_type": "code",
        "outputId": "f2145522-a187-4c79-e216-510a9c13b3a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "thurs = thurs.split('\\n\\n')\n",
        "leaves = leaves.split('\\n\\n')\n",
        "len(thurs), len(leaves)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1304, 2867)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTUUBp5F8JRe",
        "colab_type": "code",
        "outputId": "8bc89d2b-cf2e-4c45-a9dd-a1ab02926a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist([len(d) for d in thurs], bins=np.linspace(0,1000,20), histtype='step')\n",
        "plt.hist([len(d) for d in leaves], bins=np.linspace(0,1000,20), histtype='step')\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAUkklEQVR4nO3dbaxd1X3n8e+vOIEknbF58FiubcZU\nsRKhRiH0ihIRjTLQZIBUMS9ISlo1FuOR5wWd5qGj1sy8wJE6EpGquqAZMbVCWhNlQghNBotEyTCG\nqmo1oTEJAwSS4YYYbMvgWwLONE8N0/+8OMvk4F5zz73nXF/f5e9HOjprr73WPWt7W7+zzzp7n52q\nQpLUl59b6gFIkibPcJekDhnuktQhw12SOmS4S1KHViz1AADOO++82rhx41IPQ5KWlYceeuhvq2r1\nbOtOiXDfuHEj+/btW+phSNKykuTpE61zWkaSOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z\n7pLUIcNdkjp0SlyhOpadb4Gjzyy8/8rz4SOPTm48knQKGCnck3wE+DdAAY8C1wNrgTuBc4GHgN+q\nqr9PciZwB/DLwPPAr1fV/skPvTn6DOw4uvD+O1ZObiySdIqYc1omyTrgd4Cpqvol4AzgOuDjwM6q\neiPwArC1ddkKvNDqd7Z2kqSTaNQ59xXA65KsAF4PHAYuB+5u63cD17Ty5rZMW39FkkxmuJKkUcwZ\n7lV1CPhD4BkGoX6UwTTMi1X1Umt2EFjXyuuAA63vS639ucf/3STbkuxLsm9mZmbc7ZAkDRllWuZs\nBkfjFwC/ALwBuHLcF66qXVU1VVVTq1fP+nPEkqQFGmVa5leB71bVTFX9FPg8cBmwqk3TAKwHDrXy\nIWADQFu/ksEXq5Kkk2SUcH8GuDTJ69vc+RXA48ADwLWtzRbgnlbe05Zp6++vqprckCVJcxllzv1B\nBl+Mfp3BaZA/B+wCfh/4aJJpBnPqt7cutwPntvqPAtsXYdySpFcx0nnuVXUTcNNx1U8Bl8zS9sfA\n+8YfmiRpofz5AUnqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwl\nqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtSh0a5Qfabkjw89Ph+kg8nOSfJfUmebM9nt/ZJcmuS6SSP\nJLl48TdDkjRslNvsfbuqLqqqi4BfBn4IfIHB7fP2VtUmYC8/u53eVcCm9tgG3LYYA5ckndh8p2Wu\nAL5TVU8Dm4HdrX43cE0rbwbuqIGvAquSrJ3IaCVJI5lvuF8HfKaV11TV4VZ+FljTyuuAA0N9Dra6\nV0iyLcm+JPtmZmbmOQxJ0qsZOdyTvBZ4L/C549dVVQE1nxeuql1VNVVVU6tXr55PV0nSHOZz5H4V\n8PWqeq4tP3dsuqU9H2n1h4ANQ/3WtzpJ0kkyn3D/AD+bkgHYA2xp5S3APUP1H2xnzVwKHB2avpEk\nnQQrRmmU5A3Au4B/O1R9M3BXkq3A08D7W/2XgKuBaQZn1lw/sdFKkkYyUrhX1Q+Ac4+re57B2TPH\nty3ghomMTpK0IF6hKkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalD\nhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0EjhnmRVkruTfCvJE0nenuScJPclebI9n93aJsmt\nSaaTPJLk4sXdBEnS8UY9cr8F+HJVvRl4K/AEsB3YW1WbgL1tGQY30t7UHtuA2yY6YknSnOYM9yQr\ngX8B3A5QVX9fVS8Cm4Hdrdlu4JpW3gzcUQNfBVYlWTvxkUuSTmiUI/cLgBngT5N8I8kn2g2z11TV\n4dbmWWBNK68DDgz1P9jqJEknySjhvgK4GLitqt4G/ICfTcEAL98Uu+bzwkm2JdmXZN/MzMx8ukqS\n5jBKuB8EDlbVg235bgZh/9yx6Zb2fKStPwRsGOq/vtW9QlXtqqqpqppavXr1QscvSZrFnOFeVc8C\nB5K8qVVdATwO7AG2tLotwD2tvAf4YDtr5lLg6ND0jSTpJFgxYrt/B3w6yWuBp4DrGbwx3JVkK/A0\n8P7W9kvA1cA08MPWVpJ0Eo0U7lX1MDA1y6orZmlbwA1jjkuSNAavUJWkDhnuktQhw12SOmS4S1KH\nDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchw\nl6QOjRTuSfYneTTJw0n2tbpzktyX5Mn2fHarT5Jbk0wneSTJxYu5AZKkf2w+R+7/sqouqqpjt9vb\nDuytqk3A3rYMcBWwqT22AbdNarCSpNGMMy2zGdjdyruBa4bq76iBrwKrkqwd43UkSfM0argX8D+S\nPJRkW6tbU1WHW/lZYE0rrwMODPU92OpeIcm2JPuS7JuZmVnA0CVJJ7JixHbvqKpDSf4ZcF+Sbw2v\nrKpKUvN54araBewCmJqamldfSdKrG+nIvaoOtecjwBeAS4Dnjk23tOcjrfkhYMNQ9/WtTpJ0kswZ\n7knekOSfHCsD7wYeA/YAW1qzLcA9rbwH+GA7a+ZS4OjQ9I0k6SQYZVpmDfCFJMfa/7eq+nKSrwF3\nJdkKPA28v7X/EnA1MA38ELh+4qOWJL2qOcO9qp4C3jpL/fPAFbPUF3DDREYnSVoQr1CVpA4Z7pLU\nIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y\n3CWpQ4a7JHVo5HBPckaSbyS5ty1fkOTBJNNJPpvkta3+zLY83dZvXJyhS5JOZJTb7B3zIeAJ4J+2\n5Y8DO6vqziT/FdgK3NaeX6iqNya5rrX79QmO+dSy8y1w9JmF9195Pnzk0cmNR5IYMdyTrAfeA/wn\n4KMZ3FD1cuA3WpPdwA4G4b65lQHuBv5zkrTb7/Xn6DOw4+jC++9YObmxSFIz6rTMHwO/B/xDWz4X\neLGqXmrLB4F1rbwOOADQ1h9t7V8hybYk+5Lsm5mZWeDwJUmzmTPck/wacKSqHprkC1fVrqqaqqqp\n1atXT/JPS9Jpb5RpmcuA9ya5GjiLwZz7LcCqJCva0fl64FBrfwjYABxMsgJYCTw/8ZFLkk5oznCv\nqhuBGwGSvBP491X1m0k+B1wL3AlsAe5pXfa05f/V1t/f7Xz7JKw8f7x5d7+QlTSL+Zwtc7zfB+5M\n8gfAN4DbW/3twKeSTAPfA64bb4idGzeY/UJW0izmFe5V9RfAX7TyU8Als7T5MfC+CYxNkrRAXqEq\nSR0y3CWpQ+PMuXdj4/YvLrjv/rMmOBBJmhDDHdh/83sW3nnHxIYhSRPjtIwkdchwl6QOGe6S1CHD\nXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KH5gz3JGcl+Zsk/zvJ\nN5N8rNVfkOTBJNNJPpvkta3+zLY83dZvXNxNkCQdb5Qj958Al1fVW4GLgCuTXAp8HNhZVW8EXgC2\ntvZbgRda/c7WTpJ0Es0Z7jXwd23xNe1RwOXA3a1+N3BNK29uy7T1VyTJxEYsSZrTSHPuSc5I8jBw\nBLgP+A7wYlW91JocBNa18jrgAEBbfxQ4d5a/uS3JviT7ZmZmxtsKSdIrjBTuVfX/quoiYD1wCfDm\ncV+4qnZV1VRVTa1evXrcPydJGjKvs2Wq6kXgAeDtwKokx27Ttx441MqHgA0Abf1K4PmJjFaSNJJR\nzpZZnWRVK78OeBfwBIOQv7Y12wLc08p72jJt/f1VVZMctCTp1Y1yg+y1wO4kZzB4M7irqu5N8jhw\nZ5I/AL4B3N7a3w58Ksk08D3gukUYtyTpVcwZ7lX1CPC2WeqfYjD/fnz9j4H3TWR0kqQF8QpVSeqQ\n4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0a5bdldCpbeT7sWDle/488\nOrnxSDoldBHuG7d/ccF99581wYEshXGDeZw3BkmnrC7Cff/N71l45x0TG4YknTKcc5ekDhnuktQh\nw12SOjTKbfY2JHkgyeNJvpnkQ63+nCT3JXmyPZ/d6pPk1iTTSR5JcvFib4Qk6ZVGOXJ/CfjdqroQ\nuBS4IcmFwHZgb1VtAva2ZYCrgE3tsQ24beKjliS9qjnDvaoOV9XXW/n/Mrg59jpgM7C7NdsNXNPK\nm4E7auCrwKokayc+cknSCc3rVMgkGxncT/VBYE1VHW6rngXWtPI64MBQt4Ot7vBQHUm2MTiy5/zz\nz5/nsCdozIuADtZ5rJ/gcCRpEkYO9yQ/D/w58OGq+n6Sl9dVVSWp+bxwVe0CdgFMTU3Nq+9EjXkR\n0Du2f5H9kxmJJE3MSGfLJHkNg2D/dFV9vlU/d2y6pT0fafWHgA1D3de3OknSSTLK2TIBbgeeqKo/\nGlq1B9jSyluAe4bqP9jOmrkUODo0fSNJOglGmZa5DPgt4NEkD7e6/wDcDNyVZCvwNPD+tu5LwNXA\nNPBD4PqJjliSNKc5w72q/grICVZfMUv7Am4Yc1ySpDF4haokdchwl6QOdfGTv0tp3arXjfV78utW\nvY6/3n75BEckSYb72MYN5nHeGCTpRJyWkaQOGe6S1CGnZU533mBb6pLhfrrzBttSl5yWkaQOGe6S\n1CHDXZI6ZLhLUocMd0nqkOEuSR3yVEiNx/PkpVOS4a7xeJ68dEoa5TZ7n0xyJMljQ3XnJLkvyZPt\n+exWnyS3JplO8kiSixdz8JKk2Y0y5/5nwJXH1W0H9lbVJmBvWwa4CtjUHtuA2yYzTEnSfMwZ7lX1\nl8D3jqveDOxu5d3ANUP1d9TAV4FVSdZOarCSpNEsdM59TVUdbuVngTWtvA44MNTuYKs7zHGSbGNw\ndM/555+/wGFo2fMLWWlRjP2FalVVklpAv13ALoCpqal591cn/EJWWhQLDffnkqytqsNt2uVIqz8E\nbBhqt77V6QS8TZ+kxbDQcN8DbAFubs/3DNX/dpI7gV8Bjg5N32gW3qZP0mKYM9yTfAZ4J3BekoPA\nTQxC/a4kW4Gngfe35l8CrgamgR8C1y/CmCVJc5gz3KvqAydYdcUsbQu4YdxBSZLG42/LSFKH/PmB\nZc4vZCXNxnBf5k77L2Q9T16aleGu5W3cYN75Ft8c1CXDXac3L6JSpwz305xz9lKfDPfT3Gk/Zy91\nynDXkrrs5vs59OKPFtzfTw7S7Ax3LalDL/6I/Te/Z8H9/eQgzc5w11gmMWe/rI17KuakxuAZOzqO\n4a6xnPZTIqdCqHo6p2ZhuGtZ82wfPJ1TszLctax5to80O384TJI65JG7TmtO6+Dv83TKcNdp7VSY\n1lnqc/0v+8ktHPrxwl9/P7+x4L6w9NvfK8NdGsO4R/7H/sZSnus/7rUGB286j/VjHPn/NcBZC+7O\nwR+dB3xn4X9g51vg6DML7z+uRfrksyjhnuRK4BbgDOATVXXzYryOtNROhSPGpb7W4B0/uXXsN6dx\n+p+x441jTSsdZjVrdxxdcP+xLdLZShMP9yRnAP8FeBdwEPhakj1V9fikX0vS0r/BLPWby9od02P1\nv/bm+znU4fcui3HkfgkwXVVPASS5E9gMGO5Sh07FYJuPccd/2c33j/Xmtn+MKalXsxjhvg44MLR8\nEPiV4xsl2QZsa4t/l+TbC3y98/hY/naBfZer8wC3uX9u82kg42XYPz/RiiX7QrWqdgG7xv07SfZV\n1dQEhrRsuM2nB7f59LBY27wYFzEdAjYMLa9vdZKkk2Qxwv1rwKYkFyR5LXAdsGcRXkeSdAITn5ap\nqpeS/DbwFQanQn6yqr456dcZMvbUzjLkNp8e3ObTw6Jsc6pqMf6uJGkJ+cNhktQhw12SOrSswz3J\nlUm+nWQ6yfalHs8kJNmQ5IEkjyf5ZpIPtfpzktyX5Mn2fHarT5Jb27/BI0kuXtotWLgkZyT5RpJ7\n2/IFSR5s2/bZ9gU9Sc5sy9Nt/calHPdCJVmV5O4k30ryRJK3976fk3yk/b9+LMlnkpzV235O8skk\nR5I8NlQ37/2aZEtr/2SSLfMdx7IN96GfObgKuBD4QJILl3ZUE/ES8LtVdSFwKXBD267twN6q2gTs\nbcsw2P5N7bENuO3kD3liPgQ8MbT8cWBnVb0ReAHY2uq3Ai+0+p2t3XJ0C/Dlqnoz8FYG297tfk6y\nDvgdYKqqfonBCRfX0d9+/jPgyuPq5rVfk5wD3MTgAtBLgJuOvSGMrKqW5QN4O/CVoeUbgRuXelyL\nsJ33MPidnm8Da1vdWuDbrfwnwAeG2r/cbjk9GFwPsRe4HLgXCIMrFVccv78ZnIn19lZe0dplqbdh\nntu7Evju8ePueT/zs6vXz2n77V7gX/W4n4GNwGML3a/AB4A/Gap/RbtRHsv2yJ3Zf+Zg3RKNZVG0\nj6FvAx4E1lTV4bbqWWBNK/fy7/DHwO8B/9CWzwVerKqX2vLwdr28zW390dZ+ObkAmAH+tE1FfSLJ\nG+h4P1fVIeAPgWeAwwz220P0vZ+Pme9+HXt/L+dw71qSnwf+HPhwVX1/eF0N3sq7OYc1ya8BR6rq\noaUey0m0ArgYuK2q3gb8gJ99VAe63M9nM/gRwQuAXwDewD+evujeydqvyzncu/2ZgySvYRDsn66q\nz7fq55KsbevXAkdafQ//DpcB702yH7iTwdTMLcCqJMcutBverpe3ua1fCTx/Mgc8AQeBg1X1YFu+\nm0HY97yffxX4blXNVNVPgc8z2Pc97+dj5rtfx97fyzncu/yZgyQBbgeeqKo/Glq1Bzj2jfkWBnPx\nx+o/2L51vxQ4OvTxb1moqhuran1VbWSwH++vqt8EHgCubc2O3+Zj/xbXtvbL6gi3qp4FDiR5U6u6\ngsHPYne7nxlMx1ya5PXt//mxbe52Pw+Z7379CvDuJGe3TzzvbnWjW+ovHsb80uJq4P8wuMfWf1zq\n8Uxom97B4CPbI8DD7XE1g7nGvcCTwP8Ezmntw+Csoe8AjzI4E2HJt2OM7X8ncG8r/yLwN8A08Dng\nzFZ/Vluebut/canHvcBtvQjY1/b1fwfO7n0/Ax8DvgU8BnwKOLO3/Qx8hsF3Cj9l8Alt60L2K/Cv\n27ZPA9fPdxz+/IAkdWg5T8tIkk7AcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkd+v/kuRczyo3w\n2QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHMfhNO48MBV",
        "colab_type": "code",
        "outputId": "19781d84-2151-48ae-c370-17c68c6beee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist([len(d) for d in thurs if len(d)<200], bins=np.linspace(0,200,20), histtype='step')\n",
        "plt.hist([len(d) for d in leaves if len(d)<200], bins=np.linspace(0,200,20), histtype='step')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY76MAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2te1F_gZ8QDo",
        "colab_type": "code",
        "outputId": "4547767d-2ebd-4449-ab75-f30d85406ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len([d for d in thurs if len(d)>50]), len([d for d in leaves if len(d)>50])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1084, 2054)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsWKSbWc8TvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = [d for d in thurs if len(d)>50]+[d for d in leaves if len(d)>50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTaaGkuo8rIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = [' '.join(d.split()) for d in texts]\n",
        "texts = [d for d in texts if len(d)>50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mrLnAlr8yPL",
        "colab_type": "code",
        "outputId": "77b4cbbb-ca17-45fe-c55d-7b412efcdd44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "texts[10]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The man with the meek blue eyes and the pale, pointed beard endured these thunders with a certain submissive solemnity. The third party of the group, Gregory's sister Rosamond, who had her brother's braids of red hair, but a kindlier face underneath them, laughed with such mixture of admiration and disapproval as she gave commonly to the family oracle.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-TfLP3P84cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents = '\\n'.join(texts)\n",
        "sents = nltk.tokenize.sent_tokenize(sents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dMNjtnq85HH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doc2words(doc):\n",
        "  words = nltk.tokenize.word_tokenize(doc)\n",
        "  words = [w.lower() for w in words if w.isalpha()]\n",
        "  words = [w for w in words if (len(w)>1) and (w not in stopwords)]\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXikDLMM87wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents = [doc2words(s) for s in sents]\n",
        "sents = [s for s in sents if len(s)>0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCN8LPVL8_eP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb = Word2Vec(sents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aMbaP199B5e",
        "colab_type": "code",
        "outputId": "e8cd0cbc-f71d-4e37-84a9-70b0eea3dfe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "emb.wv.similar_by_word('door')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('time', 0.9998476505279541),\n",
              " ('also', 0.9998418092727661),\n",
              " ('great', 0.9998346567153931),\n",
              " ('back', 0.9998337626457214),\n",
              " ('without', 0.9998322129249573),\n",
              " ('heart', 0.9998321533203125),\n",
              " ('fill', 0.9998311996459961),\n",
              " ('would', 0.9998292922973633),\n",
              " ('may', 0.9998290538787842),\n",
              " ('round', 0.9998288750648499)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqI-Ylrx9GId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "we = {w:emb.wv.get_vector(w) for w in emb.wv.vocab}\n",
        "vec_size = emb.vector_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJjpboC_9JI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiples(it, n):\n",
        "  for k in range(len(it)-n+1):\n",
        "    yield it[k:k+n]\n",
        "\n",
        "class TLMDataGen:\n",
        "  def __init__(self, documents, word_embedding, doc2words, lm_length, token2idx, vector_size,\n",
        "               valid_num=None, valid_frac=None, batch_size=20, valid_batch_size=100):\n",
        "    if valid_num is None and valid_frac is None:\n",
        "      if len(documents) < 1000:\n",
        "        valid_num = int(0.1*len(documents))\n",
        "      else:\n",
        "        valid_num = 100\n",
        "    elif valid_num is None:\n",
        "      valid_num = int(valid_frac*len(documents))\n",
        "\n",
        "    perm = np.random.permutation(len(documents))\n",
        "    self.train_idxs = perm[:valid_num]\n",
        "    self.valid_idxs = perm[valid_num:]\n",
        "\n",
        "    rep = {'<':'*', '>':'*'}\n",
        "    rep = {re.escape(k):v for k,v in rep.items()}\n",
        "    pattern = re.compile('|'.join(rep.keys()))\n",
        "\n",
        "    self.documents = ['<'*lm_length+pattern.sub(lambda m: rep[re.escape(m.group(0))], d)+'>' for d in documents]\n",
        "    self.batch_size = batch_size\n",
        "    self.valid_batch_size = valid_batch_size\n",
        "    self.word_embedding = word_embedding\n",
        "    self.doc2words = doc2words\n",
        "    self.lm_length = lm_length\n",
        "    self.token2idx = token2idx\n",
        "    self.vector_size = vector_size\n",
        "\n",
        "  def get_train_batch(self):\n",
        "    doc_idxs = np.random.choice(self.train_idxs, size=self.batch_size)\n",
        "    docs = [self.documents[k] for k in doc_idxs]\n",
        "    finish_idxs = [np.random.randint(self.lm_length+1, len(d)) for d in docs]\n",
        "    \n",
        "    x_topic = [np.array([self.word_embedding[w] for w in self.doc2words(d) if w in self.word_embedding]) for d in docs]\n",
        "    x_topic = [d if d.shape != (0,) else np.zeros((1, self.vector_size)) for d in x_topic]\n",
        "    x_topic = [d.mean(axis=0) for d in x_topic]\n",
        "    x_topic = np.array(x_topic)\n",
        "\n",
        "    lm_docs = [d[i-self.lm_length-1:i] for i, d in zip(finish_idxs, docs)]\n",
        "    lm_docs = np.array([[self.token2idx.get(t,2) for t in d] for d in lm_docs])\n",
        "\n",
        "    return [x_topic, lm_docs[:,:-1]], lm_docs[:,1:]\n",
        "\n",
        "  def get_valid_batch(self):\n",
        "    doc_idxs = np.random.choice(self.valid_idxs, size=self.valid_batch_size)\n",
        "    docs = [self.documents[k] for k in doc_idxs]\n",
        "    finish_idxs = [np.random.randint(self.lm_length+1, len(d)) for d in docs]\n",
        "    \n",
        "    x_topic = [np.array([self.word_embedding[w] for w in self.doc2words(d) if w in self.word_embedding]) for d in docs]\n",
        "    x_topic = [d if d.shape != (0,) else np.zeros((1, self.vector_size)) for d in x_topic]\n",
        "    x_topic = [d.mean(axis=0) for d in x_topic]\n",
        "    x_topic = np.array(x_topic)\n",
        "\n",
        "    lm_docs = [d[i-self.lm_length-1:i] for i, d in zip(finish_idxs, docs)]\n",
        "    lm_docs = np.array([[self.token2idx.get(t,2) for t in d] for d in lm_docs])\n",
        "\n",
        "    return [x_topic, lm_docs[:,:-1]], lm_docs[:,1:]\n",
        "\n",
        "\n",
        "class TopicalLanguageModel:\n",
        "  \"\"\"\n",
        "  Neural Topical Language Model.\n",
        "\n",
        "  attributes:\n",
        "  num_topics :: int : number of topics\n",
        "  doc2words :: function : takes a document as a string and returns words\n",
        "  word_embedding :: dict : keys are words, values are vectors\n",
        "  vector_size :: int : the dimension of embedding vectors\n",
        "  lm_length :: int : length of tokens taken into account for character-level language models \n",
        "  \"\"\"\n",
        "  def __init__(self, num_topics, word_embedding, vector_size, doc2words, lm_length=30, tokens='abcdefghijklmnopqrstuvwxyz '):\n",
        "    self.num_topics = num_topics\n",
        "    self.doc2words = doc2words\n",
        "    self.word_embedding = word_embedding\n",
        "    self.vector_size = vector_size\n",
        "    self.lm_length = lm_length\n",
        "\n",
        "    self.tokens = ['<', '>', '*'] + list(tokens)\n",
        "    token_idx = [(t, k+3) for k,t in enumerate(list(tokens))]+[('<',0),('>',1),('*',2)]\n",
        "    self.token2idx = {t:k for t,k in token_idx}\n",
        "    self.idx2token = {k:t for t,k in token_idx}\n",
        "\n",
        "    self.num_tokens = len(tokens)+3\n",
        "\n",
        "  def fit(self, documents, batch_size=20, epochs=10, verbose=0, examples_per_epoch=5, example_epoch_skip=1, num_validation_samples=5):\n",
        "    \"\"\"\n",
        "    fit(self, documents)\n",
        "\n",
        "    documents should be a list of sentences, and a sentence a list of words.\n",
        "    \"\"\"\n",
        "    x_topic = Input(shape=(self.vector_size,))\n",
        "    h_topic = Dense(self.vector_size, activation='relu')(x_topic)\n",
        "    out_topic = Dense(self.num_topics, activation='softmax')(h_topic)\n",
        "    self.topic_model = Model(inputs=[x_topic], outputs=out_topic)\n",
        "    \n",
        "    self.language_models = []\n",
        "    for k in range(self.num_topics):\n",
        "      x_lm = Input(shape=(self.lm_length,), dtype='int32')\n",
        "      h_lm = Embedding(input_dim=self.num_tokens, output_dim=self.num_tokens//2, input_length=self.lm_length)(x_lm)\n",
        "      h_lm = LSTM(self.num_tokens, return_sequences=True)(h_lm)\n",
        "      h_lm = LSTM(self.num_tokens, return_sequences=True)(h_lm)\n",
        "      out_lm = TimeDistributed(Dense(self.num_tokens, activation='softmax'))(h_lm)\n",
        "      lm = Model(inputs=[x_lm], outputs=out_lm)\n",
        "      self.language_models.append(lm)\n",
        "\n",
        "    train_topic_input = Input(shape=(self.vector_size,))\n",
        "    train_lm_input = Input(shape=(self.lm_length,), dtype='int32')\n",
        "\n",
        "    lm_outputs = [Reshape(target_shape=(self.lm_length, self.num_tokens, 1))(lm(train_lm_input)) for lm in self.language_models]\n",
        "    lm_outputs = Concatenate(axis=3)(lm_outputs)\n",
        "    topic_mix = self.topic_model(train_topic_input)\n",
        "\n",
        "    out = Dot(axes=(3, 1), name='mixed_out')([lm_outputs, topic_mix])\n",
        "\n",
        "    self.train_model = Model(inputs=[train_topic_input, train_lm_input], outputs=[out, topic_mix])\n",
        "\n",
        "    def mix_loss(y_true, y_pred):\n",
        "      eps = 1e-10\n",
        "      mean = K.mean(y_pred, axis=0)\n",
        "\n",
        "      mean_nentropy = K.mean(K.sum(y_pred*K.log(y_pred+eps), axis=1))\n",
        "      nentropy_mean = K.sum(mean*K.log(mean+eps))\n",
        "      return nentropy_mean - mean_nentropy\n",
        "      \n",
        "\n",
        "    self.train_model.compile('adam', ['sparse_categorical_crossentropy', mix_loss])\n",
        "\n",
        "    data_generator = TLMDataGen(documents, word_embedding=self.word_embedding, \n",
        "                                doc2words=self.doc2words, \n",
        "                                lm_length=self.lm_length, \n",
        "                                token2idx=self.token2idx,\n",
        "                                vector_size=self.vector_size,\n",
        "                                batch_size = batch_size)\n",
        "\n",
        "    steps_per_epoch = len(documents)//batch_size\n",
        "    self.logs = {'examples':[], 'val_loss':[], 'topic_fraction':[], 'topic_entropy':[]}\n",
        "    for epoch in range(epochs+1):\n",
        "\n",
        "      #examples\n",
        "      if epoch%example_epoch_skip == 0:\n",
        "        if verbose>1:\n",
        "          print('Getting examples')\n",
        "        for t in range(self.num_topics):\n",
        "          for k in range(examples_per_epoch):\n",
        "            self.logs['examples'].append((self.rollout('', topic=t, maxlen=100), t, epoch))\n",
        "\n",
        "      #validation loss\n",
        "      if verbose>1:\n",
        "        print('Running validation loss')\n",
        "      xs, y = data_generator.get_valid_batch()\n",
        "      losses = [self.train_model.test_on_batch(xs, [y, np.zeros((y.shape[0], self.num_topics))]) for k in range(num_validation_samples)]\n",
        "      self.logs['val_loss'].append(losses)\n",
        "\n",
        "      #topics\n",
        "      if verbose>1:\n",
        "        print('Getting topic distributions')\n",
        "      xs, y = data_generator.get_valid_batch()\n",
        "      x = xs[0]\n",
        "      topics = self.topic_model.predict(x)\n",
        "      entropies = (-topics*np.log(topics)).sum(axis=1)\n",
        "      mean_entropy = entropies.mean(axis=0)\n",
        "      std_entropy = entropies.std(axis=0)\n",
        "      mean_topics = topics.mean(axis=0)\n",
        "      self.logs['topic_fraction'].append(mean_topics)\n",
        "      self.logs['topic_entropy'].append((mean_entropy, std_entropy))\n",
        "\n",
        "      if epoch<epochs:\n",
        "        #train\n",
        "        if verbose>1:\n",
        "          print('Training')\n",
        "        avg_loss = 0\n",
        "        for step in range(steps_per_epoch):\n",
        "          xs, y = data_generator.get_train_batch()\n",
        "          avg_loss = (step/(step+1))*avg_loss + self.train_model.train_on_batch(xs, [y, np.zeros((y.shape[0], self.num_topics))])[0]/(step+1)\n",
        "        #print\n",
        "        if verbose > 0:\n",
        "          print('Epoch {0} - Avg train loss: {1}'.format(epoch, avg_loss))\n",
        "      \n",
        "  def predict(self, init_doc, topic, method='sample'):\n",
        "    idx_doc = [self.token2idx.get(c,2) for c in init_doc]\n",
        "    dlen = len(idx_doc)\n",
        "    if dlen < self.lm_length:\n",
        "      idx_doc = [0]*(self.lm_length-dlen)+idx_doc\n",
        "    elif dlen > self.lm_length:\n",
        "      idx_doc = idx_doc[-self.lm_length:]\n",
        "\n",
        "    probs = self.language_models[topic].predict(np.array(idx_doc).reshape((1,-1)))[0,-1,:]\n",
        "\n",
        "    if method == 'sample':\n",
        "      return np.random.choice(self.tokens, p=probs)\n",
        "\n",
        "    elif method == 'max':\n",
        "      return self.tokens[np.argmax(probs)]\n",
        "\n",
        "    elif method == 'distribution':\n",
        "      return probs\n",
        "\n",
        "    else:\n",
        "      raise ValueError('Unknown method.')\n",
        "\n",
        "  def rollout(self, init_doc, topic, method='monte-carlo', maxlen=100):\n",
        "    pred_method = 'sample' if method=='monte-carlo' else 'max' if method=='greedy' else ''\n",
        "    \n",
        "    for k in range(maxlen-len(init_doc)):\n",
        "      predicted = self.predict(init_doc, topic, pred_method)\n",
        "      if predicted == '>': break\n",
        "      init_doc = init_doc + predicted\n",
        "\n",
        "    return init_doc\n",
        "\n",
        "  def get_topics(self, doc):\n",
        "    words = self.doc2words(doc)\n",
        "    embedding = np.array([self.word_embedding[w] for w in words if w in self.word_embedding]).mean(axis=0)\n",
        "    return self.topic_model.predict(embedding.reshape((-1,1)))[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp_HNWNg9fFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "tlm = TopicalLanguageModel(num_topics=2, word_embedding=we, vector_size=vec_size, doc2words=doc2words, lm_length=23)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cc412dd1-cfea-47f6-e9f5-0ab764869f2d",
        "id": "077DbzPFZlkS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "tlm.fit(texts, epochs=3, verbose=1, example_epoch_skip=1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Avg train loss: 2.93994 - Sample: m bcugpejsbs*mix*nvww nwtlfskk\n",
            "Epoch 1 - Avg train loss: 2.65349 - Sample: esisodmosyh rhegone dlpohbrns \n",
            "Epoch 2 - Avg train loss: 2.42381 - Sample: <<<<<<<<< h hn ra eneu aehlxaa\n",
            "Epoch 3 - Avg train loss: 2.32852 - Sample: <<<<<<<<<* *et tsatlr we nov a\n",
            "Epoch 4 - Avg train loss: 2.21237 - Sample: <<<<* iboy domh tougt ciper tr\n",
            "Epoch 5 - Avg train loss: 2.15179 - Sample: <<<<<*huped ose faris hef ancu\n",
            "Epoch 6 - Avg train loss: 2.09767 - Sample: <<<<<<<<*icdeeir* hhemapeo ras\n",
            "Epoch 7 - Avg train loss: 2.05141 - Sample: <** ofe casgie thod roret* arn\n",
            "Epoch 8 - Avg train loss: 1.95281 - Sample: <<<*hinos* on aml taal torliwt\n",
            "Epoch 9 - Avg train loss: 1.90687 - Sample: <**y exdell* yosd ine gin suul\n",
            "Epoch 10 - Avg train loss: 1.83596 - Sample: <<<<<<<<<<<** * * sory *o sora\n",
            "Epoch 11 - Avg train loss: 1.80042 - Sample: <<<** onnd mosesing* fibk* *re\n",
            "Epoch 12 - Avg train loss: 1.74556 - Sample: <<<<*i* *her seetill thelse th\n",
            "Epoch 13 - Avg train loss: 1.69528 - Sample: <<*hore to prho sawang as that\n",
            "Epoch 14 - Avg train loss: 1.65826 - Sample: <<<<<*eou lama so *le kifth wo\n",
            "Epoch 15 - Avg train loss: 1.63058 - Sample: <<*in theer foug to has ssos t\n",
            "Epoch 16 - Avg train loss: 1.61379 - Sample: <<<<<<<<* wans name arnitung s\n",
            "Epoch 17 - Avg train loss: 1.55322 - Sample: <<<<<<<<<<<<** *ame* has hald \n",
            "Epoch 18 - Avg train loss: 1.54330 - Sample: <<<<<<* heas four sould* bivin\n",
            "Epoch 19 - Avg train loss: 1.52602 - Sample: <<<<<<* ow the ballh ther on l\n",
            "Epoch 20 - Avg train loss: 1.52343 - Sample: *ts* ont thaiiog ths thirg all\n",
            "Epoch 21 - Avg train loss: 1.48671 - Sample: <<<**o halg witens* forvomcy a\n",
            "Epoch 22 - Avg train loss: 1.47599 - Sample: <<**r* dat ale l* novics* hae \n",
            "Epoch 23 - Avg train loss: 1.43597 - Sample: <**h* *nhert* of the hald hing\n",
            "Epoch 24 - Avg train loss: 1.43316 - Sample: <<<**aune *maves to of hits th\n",
            "Epoch 25 - Avg train loss: 1.42230 - Sample: <**ren* and cpatian* whom tist\n",
            "Epoch 26 - Avg train loss: 1.39975 - Sample: <**h* wat as shepe as ranslrin\n",
            "Epoch 27 - Avg train loss: 1.41796 - Sample: <*etherist wisht highe yrargy \n",
            "Epoch 28 - Avg train loss: 1.40645 - Sample: <<<<<*wltsiung on as tas aens \n",
            "Epoch 29 - Avg train loss: 1.37232 - Sample: <<<reosy shere gretows hiligus\n",
            "Epoch 30 - Avg train loss: 1.33686 - Sample: <<<**ushing herchiyunde* *py o\n",
            "Epoch 31 - Avg train loss: 1.34710 - Sample: **o** withuods cupy dal* * sin\n",
            "Epoch 32 - Avg train loss: 1.32968 - Sample: *hould u suns the soud * what \n",
            "Epoch 33 - Avg train loss: 1.29302 - Sample: <<<*yo hasdds* lith of tit wom\n",
            "Epoch 34 - Avg train loss: 1.29447 - Sample: <*woaun** *erris the arin ibch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-0da715c28b86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_epoch_skip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-4d0931153f94>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, documents, batch_size, epochs, verbose, examples_per_epoch, example_epoch_skip, num_validation_samples)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m           \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m           \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mavg_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m#print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mscaled_total_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0mtrainable_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# TODO(tanzheny) b/132690565: Provide mechanism for user to override\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msub_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             extra_variables=self._trainable_weights))\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mgather_trainable_weights\u001b[0;34m(trainable, sub_layers, extra_variables)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m   trainable_extra_variables = [\n\u001b[1;32m     81\u001b[0m       v for v in extra_variables if v.trainable]\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msub_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             extra_variables=self._trainable_weights))\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mgather_trainable_weights\u001b[0;34m(trainable, sub_layers, extra_variables)\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m   trainable_extra_variables = [\n\u001b[1;32m     81\u001b[0m       v for v in extra_variables if v.trainable]\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    945\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0mnested\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_children_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainable_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnested\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_gather_children_attribute\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m   2331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_layers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2332\u001b[0m       nested_layers = trackable_layer_utils.filter_empty_layer_containers(\n\u001b[0;32m-> 2333\u001b[0;31m           self._layers)\n\u001b[0m\u001b[1;32m   2334\u001b[0m       return list(\n\u001b[1;32m   2335\u001b[0m           itertools.chain.from_iterable(\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mfilter_empty_layer_containers\u001b[0;34m(layer_list)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mfiltered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m       \u001b[0;31m# Trackable data structures will not show up in \".layers\" lists, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0;31m# the layers they contain will.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/data_structures.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    691\u001b[0m       \u001b[0;31m# in particular seems to look up properties on the wrapped object instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0;31m# of the wrapper without this logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DictWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/data_structures.py\u001b[0m in \u001b[0;36mlayers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_layer_containers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/data_structures.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    691\u001b[0m       \u001b[0;31m# in particular seems to look up properties on the wrapped object instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0;31m# of the wrapper without this logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DictWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/data_structures.py\u001b[0m in \u001b[0;36m_layers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m       if (isinstance(obj, TrackableDataStructure)\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mor\u001b[0m \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m           or layer_utils.has_weights(obj)):\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mcollected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mhas_weights\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;34m\"\"\"Implicit check for Layer-like objects.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;31m# TODO(b/110718070): Replace with isinstance(obj, base_layer.Layer).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   has_weight = (hasattr(type(obj), \"trainable_weights\")\n\u001b[0m\u001b[1;32m     37\u001b[0m                 and hasattr(type(obj), \"non_trainable_weights\"))\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z61FW4lD6tVz",
        "colab_type": "code",
        "outputId": "4e1f5da0-2046-4fe6-d344-a3539f841731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "tlm.train_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 23)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Model)                 (None, 23, 30)       14220       input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Model)                 (None, 23, 30)       14220       input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 23, 30, 1)    0           model_2[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 23, 30, 1)    0           model_3[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 23, 30, 2)    0           reshape_1[0][0]                  \n",
            "                                                                 reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 2)            10302       input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "mixed_out (Dot)                 (None, 23, 30)       0           concatenate_1[0][0]              \n",
            "                                                                 model_1[1][0]                    \n",
            "==================================================================================================\n",
            "Total params: 38,742\n",
            "Trainable params: 38,742\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m45cd8An9lAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tlm.logs.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZYGuFeC9lUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "ex = pd.DataFrame(columns=['example', 'topic_num', 'epoch'], data=tlm.logs['examples'])\n",
        "ex.sample(50).sort_values('epoch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFXBO8SjcVK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(tlm.logs['val_loss']), len(tlm.logs['val_loss'][0]), len(tlm.logs['val_loss'][0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgnBZEQg9l74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_losses = [np.array(v).mean(axis=0) for v in tlm.logs['val_loss']]\n",
        "max_losses = [np.array(v).max(axis=0) for v in tlm.logs['val_loss']]\n",
        "min_losses = [np.array(v).min(axis=0) for v in tlm.logs['val_loss']]\n",
        "epoch = np.arange(len(mean_losses))\n",
        "\n",
        "fig, axs = plt.subplots(3)\n",
        "for k in range(3):\n",
        "  axs[k].plot(epoch, [m[k] for m in mean_losses], color='b')\n",
        "  axs[k].fill_between(epoch, [m[k] for m in max_losses], [m[k] for m in min_losses], color='b', alpha=0.3)\n",
        "  axs[k].set_xlabel('Epoch')\n",
        "  axs[k].set_ylabel('Loss: {}'.format(tlm.train_model.metrics_names[k]))\n",
        "\n",
        "fig.set_size_inches(12,12)\n",
        "plt.title('validation loss - max, mean, min')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIj0eHx79mLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = np.arange(len(tlm.logs['topic_entropy']))\n",
        "\n",
        "fig, ax_mean = plt.subplots()\n",
        "ax_mean.stackplot(epoch, np.array(tlm.logs['topic_fraction']).T)\n",
        "ax_mean.set_xlabel('Epoch')\n",
        "ax_mean.set_ylabel('Topic Balance')\n",
        "\n",
        "ax_ent = ax_mean.twinx()\n",
        "topic_entropy = [e[0] for e in tlm.logs['topic_entropy']]\n",
        "max_topic_entropy = [(-p*np.log(p)).sum() for p in tlm.logs['topic_fraction']]\n",
        "frac_topic_entropy = [e/m for e,m in zip(topic_entropy, max_topic_entropy)]\n",
        "ax_ent.plot(epoch, frac_topic_entropy, color='k')\n",
        "ax_ent.set_ylabel('Topic entropy/max topic entropy (for given topic balance)')\n",
        "ax_ent.set_ylim(0,1.05)\n",
        "\n",
        "fig.set_size_inches(12,6)\n",
        "fig.tight_layout()\n",
        "plt.title('topic balance estimates - max, mean, min')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8mm7fWNhaCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}