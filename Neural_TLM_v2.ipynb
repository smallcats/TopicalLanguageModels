{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_TLM_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smallcats/TopicalLanguageModels/blob/master/Neural_TLM_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTWYvbXC68CH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "387e5cd8-6fed-4a85-8b5b-32559a801760"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Flatten, Lambda, Concatenate, Reshape, Dot, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP5TY8t97Gk1",
        "colab_type": "code",
        "outputId": "25e34ec9-adb0-4e67-e4a9-777a73204648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = stopwords.words('english')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4z-eaM57HjV",
        "colab_type": "code",
        "outputId": "6ea24ec2-38aa-48b0-d803-690051f72170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "nltk.corpus.gutenberg.fileids()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq8Cw9Ct7MyJ",
        "colab_type": "code",
        "outputId": "081f37af-d6e5-4e43-fb4c-508df9a4622f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "thurs = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
        "leaves = nltk.corpus.gutenberg.raw('whitman-leaves.txt')\n",
        "len(thurs), len(leaves)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(320525, 711215)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRgEYnfL8BYe",
        "colab_type": "code",
        "outputId": "6e684a33-21a5-4b5e-95a9-c8394e912c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "thurs = thurs.split('\\n\\n')\n",
        "leaves = leaves.split('\\n\\n')\n",
        "len(thurs), len(leaves)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1304, 2867)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTUUBp5F8JRe",
        "colab_type": "code",
        "outputId": "bd9f50a3-f922-4453-d784-0c033d27b8e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist([len(d) for d in thurs], bins=np.linspace(0,1000,20), histtype='step')\n",
        "plt.hist([len(d) for d in leaves], bins=np.linspace(0,1000,20), histtype='step')\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHMfhNO48MBV",
        "colab_type": "code",
        "outputId": "a00334f5-d189-43c6-b9dd-16201f23ceac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist([len(d) for d in thurs if len(d)<200], bins=np.linspace(0,200,20), histtype='step')\n",
        "plt.hist([len(d) for d in leaves if len(d)<200], bins=np.linspace(0,200,20), histtype='step')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY76MAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2te1F_gZ8QDo",
        "colab_type": "code",
        "outputId": "4ebfb476-ff82-461e-86db-eabcdc136e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len([d for d in thurs if len(d)>50]), len([d for d in leaves if len(d)>50])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1084, 2054)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsWKSbWc8TvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = [d for d in thurs if len(d)>50]+[d for d in leaves if len(d)>50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTaaGkuo8rIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = [' '.join(d.split()) for d in texts]\n",
        "texts = [d for d in texts if len(d)>50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mrLnAlr8yPL",
        "colab_type": "code",
        "outputId": "06949396-8c30-4cec-a0b6-f20afea4908c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "texts[10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The man with the meek blue eyes and the pale, pointed beard endured these thunders with a certain submissive solemnity. The third party of the group, Gregory's sister Rosamond, who had her brother's braids of red hair, but a kindlier face underneath them, laughed with such mixture of admiration and disapproval as she gave commonly to the family oracle.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-TfLP3P84cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents = '\\n'.join(texts)\n",
        "sents = nltk.tokenize.sent_tokenize(sents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dMNjtnq85HH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doc2words(doc):\n",
        "  words = nltk.tokenize.word_tokenize(doc)\n",
        "  words = [w.lower() for w in words if w.isalpha()]\n",
        "  words = [w for w in words if (len(w)>1) and (w not in stopwords)]\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXikDLMM87wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents = [doc2words(s) for s in sents]\n",
        "sents = [s for s in sents if len(s)>0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCN8LPVL8_eP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb = Word2Vec(sents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aMbaP199B5e",
        "colab_type": "code",
        "outputId": "641ca89d-50c7-4f4c-d55a-2ec677370061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "emb.wv.similar_by_word('door')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('without', 0.9998893737792969),\n",
              " ('great', 0.9998875260353088),\n",
              " ('life', 0.9998874068260193),\n",
              " ('vast', 0.9998844861984253),\n",
              " ('yet', 0.9998835325241089),\n",
              " ('war', 0.9998832941055298),\n",
              " ('like', 0.9998816251754761),\n",
              " ('upon', 0.9998815059661865),\n",
              " ('come', 0.9998805522918701),\n",
              " ('rest', 0.9998799562454224)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqI-Ylrx9GId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "we = {w:emb.wv.get_vector(w) for w in emb.wv.vocab}\n",
        "vec_size = emb.vector_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJjpboC_9JI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiples(it, n):\n",
        "  for k in range(len(it)-n+1):\n",
        "    yield it[k:k+n]\n",
        "\n",
        "class TLMDataGen:\n",
        "  def __init__(self, documents, word_embedding, doc2words, lm_length, token2idx, vector_size,\n",
        "               valid_num=None, valid_frac=None, batch_size=20, valid_batch_size=100):\n",
        "    if valid_num is None and valid_frac is None:\n",
        "      if len(documents) < 1000:\n",
        "        valid_num = int(0.1*len(documents))\n",
        "      else:\n",
        "        valid_num = 100\n",
        "    elif valid_num is None:\n",
        "      valid_num = int(valid_frac*len(documents))\n",
        "\n",
        "    perm = np.random.permutation(len(documents))\n",
        "    self.train_idxs = perm[:valid_num]\n",
        "    self.valid_idxs = perm[valid_num:]\n",
        "\n",
        "    rep = {'<':'*', '>':'*'}\n",
        "    rep = {re.escape(k):v for k,v in rep.items()}\n",
        "    pattern = re.compile('|'.join(rep.keys()))\n",
        "\n",
        "    self.documents = ['<'*lm_length+pattern.sub(lambda m: rep[re.escape(m.group(0))], d)+'>' for d in documents]\n",
        "    self.batch_size = batch_size\n",
        "    self.valid_batch_size = valid_batch_size\n",
        "    self.word_embedding = word_embedding\n",
        "    self.doc2words = doc2words\n",
        "    self.lm_length = lm_length\n",
        "    self.token2idx = token2idx\n",
        "    self.vector_size = vector_size\n",
        "\n",
        "  def get_train_batch(self):\n",
        "    doc_idxs = np.random.choice(self.train_idxs, size=self.batch_size)\n",
        "    docs = [self.documents[k] for k in doc_idxs]\n",
        "    finish_idxs = [np.random.randint(self.lm_length+1, len(d)) for d in docs]\n",
        "    \n",
        "    x_topic = [np.array([self.word_embedding[w] for w in self.doc2words(d) if w in self.word_embedding]) for d in docs]\n",
        "    x_topic = [d if d.shape != (0,) else np.zeros((1, self.vector_size)) for d in x_topic]\n",
        "    x_topic = [d.mean(axis=0) for d in x_topic]\n",
        "    x_topic = np.array(x_topic)\n",
        "\n",
        "    lm_docs = [d[i-self.lm_length-1:i] for i, d in zip(finish_idxs, docs)]\n",
        "    lm_docs = np.array([[self.token2idx.get(t,2) for t in d] for d in lm_docs])\n",
        "\n",
        "    return [x_topic, lm_docs[:,:-1]], lm_docs[:,1:]\n",
        "\n",
        "  def get_valid_batch(self):\n",
        "    doc_idxs = np.random.choice(self.valid_idxs, size=self.valid_batch_size)\n",
        "    docs = [self.documents[k] for k in doc_idxs]\n",
        "    finish_idxs = [np.random.randint(self.lm_length+1, len(d)) for d in docs]\n",
        "    \n",
        "    x_topic = [np.array([self.word_embedding[w] for w in self.doc2words(d) if w in self.word_embedding]) for d in docs]\n",
        "    x_topic = [d if d.shape != (0,) else np.zeros((1, self.vector_size)) for d in x_topic]\n",
        "    x_topic = [d.mean(axis=0) for d in x_topic]\n",
        "    x_topic = np.array(x_topic)\n",
        "\n",
        "    lm_docs = [d[i-self.lm_length-1:i] for i, d in zip(finish_idxs, docs)]\n",
        "    lm_docs = np.array([[self.token2idx.get(t,2) for t in d] for d in lm_docs])\n",
        "\n",
        "    return [x_topic, lm_docs[:,:-1]], lm_docs[:,1:]\n",
        "\n",
        "\n",
        "class TopicalLanguageModel:\n",
        "  \"\"\"\n",
        "  Neural Topical Language Model.\n",
        "\n",
        "  attributes:\n",
        "  num_topics :: int : number of topics\n",
        "  doc2words :: function : takes a document as a string and returns words\n",
        "  word_embedding :: dict : keys are words, values are vectors\n",
        "  vector_size :: int : the dimension of embedding vectors\n",
        "  lm_length :: int : length of tokens taken into account for character-level language models \n",
        "  \"\"\"\n",
        "  def __init__(self, num_topics, word_embedding, vector_size, doc2words, lm_length=30, tokens='abcdefghijklmnopqrstuvwxyz '):\n",
        "    self.num_topics = num_topics\n",
        "    self.doc2words = doc2words\n",
        "    self.word_embedding = word_embedding\n",
        "    self.vector_size = vector_size\n",
        "    self.lm_length = lm_length\n",
        "\n",
        "    self.tokens = ['<', '>', '*'] + list(tokens)\n",
        "    token_idx = [(t, k+3) for k,t in enumerate(list(tokens))]+[('<',0),('>',1),('*',2)]\n",
        "    self.token2idx = {t:k for t,k in token_idx}\n",
        "    self.idx2token = {k:t for t,k in token_idx}\n",
        "\n",
        "    self.num_tokens = len(tokens)+3\n",
        "\n",
        "  def fit(self, documents, batch_size=20, epochs=10, verbose=0, examples_per_epoch=5, example_epoch_skip=1, num_validation_samples=5):\n",
        "    \"\"\"\n",
        "    fit(self, documents)\n",
        "\n",
        "    documents should be a list of sentences, and a sentence a list of words.\n",
        "    \"\"\"\n",
        "    x_topic = Input(shape=(self.vector_size,))\n",
        "    h_topic = Dense(self.vector_size, activation='relu')(x_topic)\n",
        "    out_topic = Dense(self.num_topics, activation='softmax')(h_topic)\n",
        "    self.topic_model = Model(inputs=[x_topic], outputs=out_topic)\n",
        "    \n",
        "    self.language_models = []\n",
        "    for k in range(self.num_topics):\n",
        "      x_lm = Input(shape=(self.lm_length,), dtype='int32')\n",
        "      h_lm = Embedding(input_dim=self.num_tokens, output_dim=self.num_tokens//2, input_length=self.lm_length)(x_lm)\n",
        "      h_lm = LSTM(self.num_tokens, return_sequences=True)(h_lm)\n",
        "      h_lm = LSTM(self.num_tokens, return_sequences=True)(h_lm)\n",
        "      out_lm = TimeDistributed(Dense(self.num_tokens, activation='softmax'))(h_lm)\n",
        "      lm = Model(inputs=[x_lm], outputs=out_lm)\n",
        "      self.language_models.append(lm)\n",
        "\n",
        "    train_topic_input = Input(shape=(self.vector_size,))\n",
        "    train_lm_input = Input(shape=(self.lm_length,), dtype='int32')\n",
        "\n",
        "    lm_outputs = [Reshape(target_shape=(self.lm_length, self.num_tokens, 1))(lm(train_lm_input)) for lm in self.language_models]\n",
        "    lm_outputs = Concatenate(axis=3)(lm_outputs)\n",
        "    topic_mix = self.topic_model(train_topic_input)\n",
        "\n",
        "    out = Dot(axes=(3, 1), name='mixed_out')([lm_outputs, topic_mix])\n",
        "\n",
        "    self.train_model = Model(inputs=[train_topic_input, train_lm_input], outputs=[out, topic_mix])\n",
        "\n",
        "    def mix_loss(y_true, y_pred):\n",
        "      eps = 1e-10\n",
        "      mean = K.mean(y_pred, axis=0)\n",
        "\n",
        "      mean_nentropy = K.mean(K.sum(y_pred*K.log(y_pred+eps), axis=1))\n",
        "      nentropy_mean = K.sum(mean*K.log(mean+eps))\n",
        "      return nentropy_mean - mean_nentropy\n",
        "      \n",
        "\n",
        "    self.train_model.compile('adam', ['sparse_categorical_crossentropy', mix_loss])\n",
        "\n",
        "    data_generator = TLMDataGen(documents, word_embedding=self.word_embedding, \n",
        "                                doc2words=self.doc2words, \n",
        "                                lm_length=self.lm_length, \n",
        "                                token2idx=self.token2idx,\n",
        "                                vector_size=self.vector_size,\n",
        "                                batch_size = batch_size)\n",
        "\n",
        "    steps_per_epoch = len(documents)//batch_size\n",
        "    self.logs = {'examples':[], 'val_loss':[], 'topic_fraction':[], 'topic_entropy':[]}\n",
        "    for epoch in range(epochs+1):\n",
        "\n",
        "      #examples\n",
        "      if epoch%example_epoch_skip == 0:\n",
        "        if verbose>1:\n",
        "          print('Getting examples')\n",
        "        for t in range(self.num_topics):\n",
        "          for k in range(examples_per_epoch):\n",
        "            self.logs['examples'].append((self.rollout('', topic=t, maxlen=100), t, epoch))\n",
        "\n",
        "      #validation loss\n",
        "      if verbose>1:\n",
        "        print('Running validation loss')\n",
        "      xs, y = data_generator.get_valid_batch()\n",
        "      losses = [self.train_model.test_on_batch(xs, [y, np.zeros((y.shape[0], self.num_topics))]) for k in range(num_validation_samples)]\n",
        "      self.logs['val_loss'].append(losses)\n",
        "\n",
        "      #topics\n",
        "      if verbose>1:\n",
        "        print('Getting topic distributions')\n",
        "      xs, y = data_generator.get_valid_batch()\n",
        "      x = xs[0]\n",
        "      topics = self.topic_model.predict(x)\n",
        "      entropies = (-topics*np.log(topics)).sum(axis=1)\n",
        "      mean_entropy = entropies.mean(axis=0)\n",
        "      std_entropy = entropies.std(axis=0)\n",
        "      mean_topics = topics.mean(axis=0)\n",
        "      self.logs['topic_fraction'].append(mean_topics)\n",
        "      self.logs['topic_entropy'].append((mean_entropy, std_entropy))\n",
        "\n",
        "      if epoch<epochs:\n",
        "        #train\n",
        "        if verbose>1:\n",
        "          print('Training')\n",
        "        avg_loss = 0\n",
        "        for step in range(steps_per_epoch):\n",
        "          xs, y = data_generator.get_train_batch()\n",
        "          avg_loss = (step/(step+1))*avg_loss + self.train_model.train_on_batch(xs, [y, np.zeros((y.shape[0], self.num_topics))])[0]/(step+1)\n",
        "        #print\n",
        "        if verbose > 0:\n",
        "          if epoch%example_epoch_skip == 0:\n",
        "            print('Epoch {0} - Avg train loss: {1:1.5f} - Sample: {2}'.format(epoch, avg_loss, self.logs['examples'][-1][0][:self.lm_length]))\n",
        "          else:\n",
        "            print('Epoch {0} - Avg train loss: {1}'.format(epoch, avg_loss))\n",
        "      \n",
        "  def predict(self, init_doc, topic, method='sample'):\n",
        "    idx_doc = [self.token2idx.get(c,2) for c in init_doc]\n",
        "    dlen = len(idx_doc)\n",
        "    if dlen < self.lm_length:\n",
        "      idx_doc = [0]*(self.lm_length-dlen)+idx_doc\n",
        "    elif dlen > self.lm_length:\n",
        "      idx_doc = idx_doc[-self.lm_length:]\n",
        "\n",
        "    probs = self.language_models[topic].predict(np.array(idx_doc).reshape((1,-1)))[0,-1,:]\n",
        "\n",
        "    if method == 'sample':\n",
        "      return np.random.choice(self.tokens, p=probs)\n",
        "\n",
        "    elif method == 'max':\n",
        "      return self.tokens[np.argmax(probs)]\n",
        "\n",
        "    elif method == 'distribution':\n",
        "      return probs\n",
        "\n",
        "    else:\n",
        "      raise ValueError('Unknown method.')\n",
        "\n",
        "  def rollout(self, init_doc, topic, method='monte-carlo', maxlen=100):\n",
        "    pred_method = 'sample' if method=='monte-carlo' else 'max' if method=='greedy' else ''\n",
        "    \n",
        "    for k in range(maxlen-len(init_doc)):\n",
        "      predicted = self.predict(init_doc, topic, pred_method)\n",
        "      if predicted == '>': break\n",
        "      init_doc = init_doc + predicted\n",
        "\n",
        "    return init_doc\n",
        "\n",
        "  def get_topics(self, doc):\n",
        "    words = self.doc2words(doc)\n",
        "    embedding = np.array([self.word_embedding[w] for w in words if w in self.word_embedding]).mean(axis=0)\n",
        "    return self.topic_model.predict(embedding.reshape((-1,1)))[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp_HNWNg9fFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "tlm = TopicalLanguageModel(num_topics=2, word_embedding=we, vector_size=vec_size, doc2words=doc2words, lm_length=40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "037e9e81-3b95-458b-da27-3d83b3bd6031",
        "id": "077DbzPFZlkS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tlm.fit(texts, epochs=300, verbose=1, example_epoch_skip=1, examples_per_epoch=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Avg train loss: 2.83731 - Sample: pkna\n",
            "Epoch 1 - Avg train loss: 2.53682 - Sample: p*a*uel*al*t*il***ik fi*ilwh*nan siw* **\n",
            "Epoch 2 - Avg train loss: 2.33317 - Sample: r *ea *c  ec<*tgoea  hne mlui ocutldeh o\n",
            "Epoch 3 - Avg train loss: 2.05266 - Sample: *<*arch mtdishtu  srh lc viloz iotinen*e\n",
            "Epoch 4 - Avg train loss: 1.86163 - Sample: <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<* mofa\n",
            "Epoch 5 - Avg train loss: 1.76716 - Sample: <*apud rahhesd it lon dninsksrnuors anea\n",
            "Epoch 6 - Avg train loss: 1.66156 - Sample: <<<<<<<<<<<<<<<<<<<<<<<<<<<* warmtd*e ou\n",
            "Epoch 7 - Avg train loss: 1.62274 - Sample: <<<<<<<<<* ssas fowin on vaf* ce fi wyed\n",
            "Epoch 8 - Avg train loss: 1.57240 - Sample: <<<<<<*malosdtalesy* * wos ** sy rtesde \n",
            "Epoch 9 - Avg train loss: 1.50319 - Sample: <<<<<<<<<<<<<<<<<<<<<<<<<<* a laee lecs \n",
            "Epoch 10 - Avg train loss: 1.46995 - Sample: <<<<<<<<<<<<<<<<<<*** in * *ledhis hes t\n",
            "Epoch 11 - Avg train loss: 1.43818 - Sample: <<<*** <g bacle myomros thalls* mndep sy\n",
            "Epoch 12 - Avg train loss: 1.40760 - Sample: <<*o hhed and *is cerer fot taat saun* m\n",
            "Epoch 13 - Avg train loss: 1.38712 - Sample: <<<<<* * ce theduns* *nere* mand you hhe\n",
            "Epoch 14 - Avg train loss: 1.35984 - Sample: <<<<<<*llm and *oin* *al dor pfichond ci\n",
            "Epoch 15 - Avg train loss: 1.38272 - Sample: <<<<** am chuadl thy tanssdy* is oirs th\n",
            "Epoch 16 - Avg train loss: 1.33163 - Sample: <<*n pouler* fankey* an of our fore teri\n",
            "Epoch 17 - Avg train loss: 1.30610 - Sample: <<<<<<<i<<<<<<<<<<<<<<<<<<<<<<<<*ho banc\n",
            "Epoch 18 - Avg train loss: 1.31606 - Sample: <<<<<<<<<<* loushat unel* * ewasll* lofe\n",
            "Epoch 19 - Avg train loss: 1.27920 - Sample: *s* rot ghered thnat etishe scuter** *ip\n",
            "Epoch 20 - Avg train loss: 1.28503 - Sample: <*t* *ely fome ard bing saymn**er* *ofir\n",
            "Epoch 21 - Avg train loss: 1.30111 - Sample: *e*ald meviched* at thai the tof* as rof\n",
            "Epoch 22 - Avg train loss: 1.25215 - Sample: <<*l of ance on souce tait a smal** **e \n",
            "Epoch 23 - Avg train loss: 1.22616 - Sample: <<<<<<<<<<<<<<*hi erichend *olitlhing ou\n",
            "Epoch 24 - Avg train loss: 1.24355 - Sample: * atar me the seasq* *here mamenes pret \n",
            "Epoch 25 - Avg train loss: 1.24165 - Sample: <<** am nowaspery deenevs seant goxomed \n",
            "Epoch 26 - Avg train loss: 1.19121 - Sample: <<<<<<* breo eneg gastact at the sof fca\n",
            "Epoch 27 - Avg train loss: 1.20523 - Sample: <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "Epoch 28 - Avg train loss: 1.18377 - Sample: <<<<<*lal angy an in o les wrofs in and \n",
            "Epoch 29 - Avg train loss: 1.14935 - Sample: *ha fave *yringisy leoul ffyesp* and the\n",
            "Epoch 30 - Avg train loss: 1.15375 - Sample: <**or a feorenss us sounds gillpumlmnl* \n",
            "Epoch 31 - Avg train loss: 1.14192 - Sample: <<<<<*he deaw** *ncann* dosty * mut cerm\n",
            "Epoch 32 - Avg train loss: 1.12897 - Sample: <<<<* s* *ald to greamorsong to fontins*\n",
            "Epoch 33 - Avg train loss: 1.12166 - Sample: <<<<<**om burleawlar* * soid chan hesing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 34 - Avg train loss: 1.12903 - Sample: <<*hibltes a male* * feind* anm hais cra\n",
            "Epoch 35 - Avg train loss: 1.12532 - Sample: <*hand and the chrusting exit moin is th\n",
            "Epoch 36 - Avg train loss: 1.10902 - Sample: <*he a dinl*ting** *roy to he ellard the\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 37 - Avg train loss: 1.08793 - Sample: <<<<<<<<<<<<<<<<<<<<<<<<*he parsetipher \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 38 - Avg train loss: 1.07921 - Sample: * *are* * leads whaint srow the creat of\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 39 - Avg train loss: 1.08023 - Sample: <<<<<<<<<<**hlim of the dard* feal arthe\n",
            "Epoch 40 - Avg train loss: 1.08402 - Sample: *o aw gollan and you * wupjistel fenly a\n",
            "Epoch 41 - Avg train loss: 1.07090 - Sample: <<<<<<<<<<<<<<***s anrtile cisly* *or ti\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 42 - Avg train loss: 1.05541 - Sample: *enly*s mugher welpaos conest digm* ges \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 43 - Avg train loss: 1.04100 - Sample: <*he ladtacen he *adu* and roisk* *or an\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 44 - Avg train loss: 1.04321 - Sample: **sed siss* *ver ich a bad you undear* *\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 45 - Avg train loss: 1.03652 - Sample: <<<<<<<<<<<<* diar on dised mass halqy u\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 46 - Avg train loss: 1.00455 - Sample: <<<<<<<<<<<<<<<<<<*promhoton*s me* stor \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 47 - Avg train loss: 1.00814 - Sample: **s laon exit intingrester** *e *e on in\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 48 - Avg train loss: 0.98774 - Sample: <<*nd the badses he usmirard my sond** *\n",
            "Epoch 49 - Avg train loss: 0.98283 - Sample: *ver and outge tull* the thare on* *he m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 50 - Avg train loss: 0.98211 - Sample: <** *panging the basiliss and chiin trut\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 51 - Avg train loss: 0.97861 - Sample: *amerpan*dones* *he cosecarkcing and the\n",
            "Epoch 52 - Avg train loss: 0.95358 - Sample: *ome and hard* hel ask the *o a youl* * \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 53 - Avg train loss: 0.95033 - Sample: <<<<<<<<*toht me stuswill ronted* *n *er\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 54 - Avg train loss: 0.93950 - Sample: <<*hor the reack* **ledy do *he wair* an\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 55 - Avg train loss: 0.92689 - Sample: <<<<<<<*naamy thing of hord**lle ywrmefs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 56 - Avg train loss: 0.95361 - Sample: * lin hend fhands and tacriln*s*e* an th\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 57 - Avg train loss: 0.93363 - Sample: *play and on the seeedvling* *r greather\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 58 - Avg train loss: 0.94221 - Sample: *omely and ore of anqy digh ase the dess\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 59 - Avg train loss: 0.91388 - Sample: **as leusf ase of malessoling me* *on bl\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 60 - Avg train loss: 0.90642 - Sample: <<<<**plasely eils eostill hellfous you \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 61 - Avg train loss: 0.91999 - Sample: <<<<**tss beery ravl* stron*d loy a butd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 62 - Avg train loss: 0.88785 - Sample: <**wha daof maid a you joobser a darplin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 63 - Avg train loss: 0.88362 - Sample: <<<<<**ld peame creathing the canting a \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 64 - Avg train loss: 0.86787 - Sample: <<<**pafian ry uny* doungfe* the mom and\n",
            "Epoch 65 - Avg train loss: 0.86238 - Sample: <<<**t* said dister* **an a scandiby* se\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 66 - Avg train loss: 0.86597 - Sample: **that the your bid whand lravetoors and\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 67 - Avg train loss: 0.85866 - Sample: <*han gles* *r cones* of figrowed the no\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 68 - Avg train loss: 0.83513 - Sample: <<<* am man you swead* anguretre*her bei\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 69 - Avg train loss: 0.86833 - Sample: <<<<<<<<<<<<<<**rm hand conk** stribcses\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 70 - Avg train loss: 0.82774 - Sample: <*hfar ongings* *rvard*bt meaces* and tt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 71 - Avg train loss: 0.84402 - Sample: <<**f to wand ot one flugh fore wislom n\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 72 - Avg train loss: 0.81486 - Sample: <<* laad gifr farlfiness to ge trans* st\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 73 - Avg train loss: 0.79869 - Sample: <*s at dise meas poon * *hitimarentle* *\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 74 - Avg train loss: 0.80830 - Sample: <<<<<*faster* * uptull you ase yout havy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 75 - Avg train loss: 0.80565 - Sample: *merand he canphe**angs of syout sauster\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 76 - Avg train loss: 0.81019 - Sample: <<<<*l had dise *iclal and exord** bworp\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 77 - Avg train loss: 0.79523 - Sample: <<*oor tile marveburitt as the but* *erc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 78 - Avg train loss: 0.78041 - Sample: <<*oman you conme* *e tele charpble* **a\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 79 - Avg train loss: 0.78632 - Sample: *hard at heald* and ly the caressy dave \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 80 - Avg train loss: 0.78965 - Sample: <* loidronds* *areld benenine me* the to\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 81 - Avg train loss: 0.77982 - Sample: <**t a *anying the eacaten*on you your a\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 82 - Avg train loss: 0.75549 - Sample: **ls *orote of atdhinging pader*d har hy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 83 - Avg train loss: 0.76620 - Sample: <<<* worm pite* thed* inith had as sleet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 84 - Avg train loss: 0.76158 - Sample: * and il *uvilbry under froes* *nd wiso \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 85 - Avg train loss: 0.73525 - Sample: <<<<<<<<<<<<<<<<<<<*he mad the usual tio\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 86 - Avg train loss: 0.73419 - Sample: <<<<<<<**stit easisl hairy sou tharfsaug\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 87 - Avg train loss: 0.74577 - Sample: <<* chanling foroibrery* and in toy defa\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 88 - Avg train loss: 0.73083 - Sample: <**ow * sa link* *ime on are the had as \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 89 - Avg train loss: 0.73470 - Sample: <***s ta barthw tack* the padn of oftach\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 90 - Avg train loss: 0.71541 - Sample: <<<*here at me chinls* **eres the lost m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 91 - Avg train loss: 0.71498 - Sample: <<<<<<<* for hid of the strapmas* and ha\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 92 - Avg train loss: 0.72444 - Sample: *an ny so manging the moor* * weand buce\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 93 - Avg train loss: 0.71324 - Sample: *talt a loied refwithrophe* ecwirld to a\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 94 - Avg train loss: 0.69878 - Sample: *ar le* gise conmipe* **ilipres* * meaza\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 95 - Avg train loss: 0.71868 - Sample: *ndon noung on ed thot to dee* saud*d sw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 96 - Avg train loss: 0.69866 - Sample: <<*all to do buidite one in there exinwi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 97 - Avg train loss: 0.71272 - Sample: * am ard brang* eeas* cot mang* *res* * \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 98 - Avg train loss: 0.70464 - Sample: <* east and gone and pover the hal of ou\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 99 - Avg train loss: 0.69160 - Sample: <<<<<<<<<<*oar of you waiyl the seeares \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 100 - Avg train loss: 0.67802 - Sample: **arhatuan you ranger* *he spulk* sturor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 101 - Avg train loss: 0.68010 - Sample: <<* am ap planbing** vis of the bulls* *\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 102 - Avg train loss: 0.68156 - Sample: <<<<<<<<<<<<<*erank been in rosh flanger\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 103 - Avg train loss: 0.66697 - Sample: *he amn gone* *eapaces of neint over the\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 104 - Avg train loss: 0.64986 - Sample: *he allecher and on *e you colaly slefve\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 105 - Avg train loss: 0.65627 - Sample: <<**ot so so *e svad uplormlitt and and \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 106 - Avg train loss: 0.65784 - Sample: <<<<<<<<<<**ent a danding the hild and i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z61FW4lD6tVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tlm.train_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m45cd8An9lAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tlm.logs.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZYGuFeC9lUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "ex = pd.DataFrame(columns=['example', 'topic_num', 'epoch'], data=tlm.logs['examples'])\n",
        "ex.sample(50).sort_values('epoch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFXBO8SjcVK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(tlm.logs['val_loss']), len(tlm.logs['val_loss'][0]), len(tlm.logs['val_loss'][0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgnBZEQg9l74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_losses = [np.array(v).mean(axis=0) for v in tlm.logs['val_loss']]\n",
        "max_losses = [np.array(v).max(axis=0) for v in tlm.logs['val_loss']]\n",
        "min_losses = [np.array(v).min(axis=0) for v in tlm.logs['val_loss']]\n",
        "epoch = np.arange(len(mean_losses))\n",
        "\n",
        "fig, axs = plt.subplots(3)\n",
        "for k in range(3):\n",
        "  axs[k].plot(epoch, [m[k] for m in mean_losses], color='b')\n",
        "  axs[k].fill_between(epoch, [m[k] for m in max_losses], [m[k] for m in min_losses], color='b', alpha=0.3)\n",
        "  axs[k].set_xlabel('Epoch')\n",
        "  axs[k].set_ylabel('Loss: {}'.format(tlm.train_model.metrics_names[k]))\n",
        "\n",
        "fig.set_size_inches(12,12)\n",
        "plt.title('validation loss - max, mean, min')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIj0eHx79mLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = np.arange(len(tlm.logs['topic_entropy']))\n",
        "\n",
        "fig, ax_mean = plt.subplots()\n",
        "ax_mean.stackplot(epoch, np.array(tlm.logs['topic_fraction']).T)\n",
        "ax_mean.set_xlabel('Epoch')\n",
        "ax_mean.set_ylabel('Topic Balance')\n",
        "\n",
        "ax_ent = ax_mean.twinx()\n",
        "topic_entropy = [e[0] for e in tlm.logs['topic_entropy']]\n",
        "max_topic_entropy = [(-p*np.log(p)).sum() for p in tlm.logs['topic_fraction']]\n",
        "frac_topic_entropy = [e/m for e,m in zip(topic_entropy, max_topic_entropy)]\n",
        "ax_ent.plot(epoch, frac_topic_entropy, color='k')\n",
        "ax_ent.set_ylabel('Topic entropy/max topic entropy (for given topic balance)')\n",
        "ax_ent.set_ylim(0,1.05)\n",
        "\n",
        "fig.set_size_inches(12,6)\n",
        "fig.tight_layout()\n",
        "plt.title('topic balance estimates - max, mean, min')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}