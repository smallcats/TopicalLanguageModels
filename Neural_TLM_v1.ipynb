{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_TLM_v1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smallcats/TopicalLanguageModels/blob/master/Neural_TLM_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFAvBLHfcmrD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f5bb84e-4feb-4f9c-d784-e7debe30e7ac"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, Flatten, Lambda, Concatenate, Reshape, Dot\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "\n",
        "from gensim.models import FastText\n",
        "from gensim.test.utils import common_corpus\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjRlyo009h4g",
        "colab_type": "code",
        "outputId": "be77e17e-0ab5-4f18-80cd-95d83e2f1cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('gutenberg')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-04uRZH79iY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab192c0b-114a-49c7-f7af-c98d92a1b055"
      },
      "source": [
        "thurs = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
        "len(thurs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "320525"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQN8KBSq-AnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d484840-d196-48a7-fa1e-66446a6616f3"
      },
      "source": [
        "thurs = thurs.split('\\n\\n')\n",
        "len(thurs)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "32f03aaf-f90c-4136-fd1b-05b70e7444db",
        "id": "TuZus5wfdL35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.hist([len(d) for d in thurs], bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD/9JREFUeJzt3W2MXFd9x/HvrzFJK0DYSbaWZZs6\nFKsob0isVQgCoZaIkIeqTiWIUlWNlVrym1CBaNWa8qJU6oukUkmJVEVySVoHUUIUQLEgBVwThPoi\ngQ0E58GELGki23LihTwAjYAG/n0xx/XE9WZnvbPe7NnvRxrdc889d+45VzO/vT5zZ5yqQpLUr19b\n6g5IkhaXQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknq3Kql7gDAueeeW5s2bVrq\nbkjSsvLAAw/8sKom5mr3qgj6TZs2MTU1tdTdkKRlJclTo7Rz6kaSOmfQS1LnDHpJ6pxBL0mdM+gl\nqXMGvSR1zqCXpM4Z9JLUOYNekjr3qvhm7EJs2vmlBe3/5A1XjqknkvTq5BW9JHXOoJekzhn0ktQ5\ng16SOjdS0CdZneSuJN9LciDJ25OcnWRvksfbck1rmyQ3J5lOsj/JlsUdgiTplYx6Rf8J4MtV9Rbg\nrcABYCewr6o2A/vaOsDlwOb22AHcMtYeS5LmZc6gT/IG4F3ArQBV9Yuqeh7YCuxuzXYDV7XyVuD2\nGrgPWJ1k3dh7LkkayShX9OcBM8C/JPlOkk8meS2wtqqOtDZPA2tbeT1wcGj/Q61OkrQERgn6VcAW\n4JaquhD4b45P0wBQVQXUfA6cZEeSqSRTMzMz89lVkjQPowT9IeBQVd3f1u9iEPzPHJuSacujbfth\nYOPQ/hta3ctU1a6qmqyqyYmJOf9vW0nSKZoz6KvqaeBgkt9pVZcAjwJ7gG2tbhtwdyvvAa5td99c\nDLwwNMUjSTrNRv2tmz8DPp3kTOAJ4DoGfyTuTLIdeAq4urW9B7gCmAZebG0lSUtkpKCvqgeByZNs\nuuQkbQu4foH9kiSNid+MlaTOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0\nktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9J\nnTPoJalzBr0kdW6koE/yZJKHkjyYZKrVnZ1kb5LH23JNq0+Sm5NMJ9mfZMtiDkCS9Mrmc0X/e1V1\nQVVNtvWdwL6q2gzsa+sAlwOb22MHcMu4OitJmr+FTN1sBXa38m7gqqH622vgPmB1knULOI4kaQFG\nDfoCvprkgSQ7Wt3aqjrSyk8Da1t5PXBwaN9DrU6StARWjdjunVV1OMlvAnuTfG94Y1VVkprPgdsf\njB0Ab3zjG+ezqyRpHka6oq+qw215FPgCcBHwzLEpmbY82pofBjYO7b6h1Z34nLuqarKqJicmJk59\nBJKkVzRn0Cd5bZLXHysDlwIPA3uAba3ZNuDuVt4DXNvuvrkYeGFoikeSdJqNMnWzFvhCkmPt/62q\nvpzkW8CdSbYDTwFXt/b3AFcA08CLwHVj77UkaWRzBn1VPQG89ST1PwIuOUl9AdePpXeSpAXzm7GS\n1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0md\nM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOjRz0Sc5I\n8p0kX2zr5yW5P8l0ks8mObPVn9XWp9v2TYvTdUnSKOZzRf9B4MDQ+o3ATVX1ZuA5YHur3w481+pv\nau0kSUtkpKBPsgG4EvhkWw/wbuCu1mQ3cFUrb23rtO2XtPaSpCUw6hX9PwJ/CfyqrZ8DPF9VL7X1\nQ8D6Vl4PHARo219o7SVJS2DOoE/y+8DRqnpgnAdOsiPJVJKpmZmZcT61JGnIKFf07wD+IMmTwB0M\npmw+AaxOsqq12QAcbuXDwEaAtv0NwI9OfNKq2lVVk1U1OTExsaBBSJJmN2fQV9VHqmpDVW0CrgG+\nVlV/DNwLvK812wbc3cp72jpt+9eqqsbaa0nSyBZyH/1fAR9OMs1gDv7WVn8rcE6r/zCwc2FdlCQt\nxKq5mxxXVV8Hvt7KTwAXnaTNz4D3j6FvkqQx8JuxktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMG\nvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BL\nUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzs0Z9El+Pck3k3w3ySNJ/rbVn5fk/iTTST6b5MxWf1Zb\nn27bNy3uECRJr2SUK/qfA++uqrcCFwCXJbkYuBG4qareDDwHbG/ttwPPtfqbWjtJ0hKZM+hr4Kdt\n9TXtUcC7gbta/W7gqlbe2tZp2y9JkrH1WJI0LyPN0Sc5I8mDwFFgL/AD4Pmqeqk1OQSsb+X1wEGA\ntv0F4JxxdlqSNLqRgr6qfllVFwAbgIuAtyz0wEl2JJlKMjUzM7PQp5MkzWJed91U1fPAvcDbgdVJ\nVrVNG4DDrXwY2AjQtr8B+NFJnmtXVU1W1eTExMQpdl+SNJdR7rqZSLK6lX8DeA9wgEHgv6812wbc\n3cp72jpt+9eqqsbZaUnS6FbN3YR1wO4kZzD4w3BnVX0xyaPAHUn+DvgOcGtrfyvwqSTTwLPANYvQ\nb0nSiOYM+qraD1x4kvonGMzXn1j/M+D9Y+mdJGnB/GasJHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ\n6two99F3bdPOL53yvk/ecOUYeyJJi8MreknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQ\nS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SercnEGfZGOSe5M8muSR\nJB9s9Wcn2Zvk8bZc0+qT5OYk00n2J9my2IOQJM1ulCv6l4A/r6rzgYuB65OcD+wE9lXVZmBfWwe4\nHNjcHjuAW8bea0nSyOYM+qo6UlXfbuWfAAeA9cBWYHdrthu4qpW3ArfXwH3A6iTrxt5zSdJI5jVH\nn2QTcCFwP7C2qo60TU8Da1t5PXBwaLdDrU6StARGDvokrwM+B3yoqn48vK2qCqj5HDjJjiRTSaZm\nZmbms6skaR5GCvokr2EQ8p+uqs+36meOTcm05dFWfxjYOLT7hlb3MlW1q6omq2pyYmLiVPsvSZrD\nKHfdBLgVOFBVHx/atAfY1srbgLuH6q9td99cDLwwNMUjSTrNVo3Q5h3AnwAPJXmw1f01cANwZ5Lt\nwFPA1W3bPcAVwDTwInDdWHssSZqXOYO+qv4TyCybLzlJ+wKuX2C/JElj4jdjJalzBr0kdc6gl6TO\nGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxB\nL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS51YtdQeWs007v3TK+z55w5Vj7Ikkzc4reknq\n3JxBn+S2JEeTPDxUd3aSvUkeb8s1rT5Jbk4ynWR/ki2L2XlJ0txGuaL/V+CyE+p2AvuqajOwr60D\nXA5sbo8dwC3j6aYk6VTNGfRV9Q3g2ROqtwK7W3k3cNVQ/e01cB+wOsm6cXVWkjR/pzpHv7aqjrTy\n08DaVl4PHBxqd6jVSZKWyII/jK2qAmq++yXZkWQqydTMzMxCuyFJmsWpBv0zx6Zk2vJoqz8MbBxq\nt6HV/T9VtauqJqtqcmJi4hS7IUmay6neR78H2Abc0JZ3D9V/IMkdwNuAF4ameDTEe/AlnS5zBn2S\nzwC/C5yb5BDwNwwC/s4k24GngKtb83uAK4Bp4EXgukXosyRpHuYM+qr6o1k2XXKStgVcv9BOSZLG\nx2/GSlLnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6Seqc/zn4MuQPokma\nD6/oJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUue8vXKFWcitmeDtmdJyZNDrtPH+f2lpGPSal4X+\ni0DS6eccvSR1zqCXpM4Z9JLUOYNekjq3KB/GJrkM+ARwBvDJqrphMY6jlWO5fgjs3UJ6NRh70Cc5\nA/gn4D3AIeBbSfZU1aPjPpb0auctpXo1WIwr+ouA6ap6AiDJHcBWwKCX5sE/EhqXxQj69cDBofVD\nwNsW4TiSZrESp7pW4phHtWRfmEqyA9jRVn+a5LFTfKpzgR+Op1fLnufiOM/FccvmXOTGRT/Eq+5c\nLHDMvzVKo8UI+sPAxqH1Da3uZapqF7BroQdLMlVVkwt9nh54Lo7zXBznuThupZ6Lxbi98lvA5iTn\nJTkTuAbYswjHkSSNYOxX9FX1UpIPAF9hcHvlbVX1yLiPI0kazaLM0VfVPcA9i/HcJ7Hg6Z+OeC6O\n81wc57k4bkWei1TVUvdBkrSI/AkESercsg76JJcleSzJdJKdS92f0yHJk0keSvJgkqlWd3aSvUke\nb8s1rT5Jbm7nZ3+SLUvb+4VJcluSo0keHqqb99iTbGvtH0+ybSnGslCznIuPJTncXhsPJrliaNtH\n2rl4LMl7h+qX9XsoycYk9yZ5NMkjST7Y6lfk62JWVbUsHww+6P0B8CbgTOC7wPlL3a/TMO4ngXNP\nqPt7YGcr7wRubOUrgH8HAlwM3L/U/V/g2N8FbAEePtWxA2cDT7TlmlZes9RjG9O5+BjwFydpe357\nf5wFnNfeN2f08B4C1gFbWvn1wPfbeFfk62K2x3K+ov+/n1qoql8Ax35qYSXaCuxu5d3AVUP1t9fA\nfcDqJOuWooPjUFXfAJ49oXq+Y38vsLeqnq2q54C9wGWL3/vxmuVczGYrcEdV/byq/guYZvD+Wfbv\noao6UlXfbuWfAAcYfDt/Rb4uZrOcg/5kP7Wwfon6cjoV8NUkD7RvFwOsraojrfw0sLaVV8I5mu/Y\nez8nH2hTErcdm65ghZyLJJuAC4H78XXxMss56Feqd1bVFuBy4Pok7xreWIN/h67IW6lW8tibW4Df\nBi4AjgD/sLTdOX2SvA74HPChqvrx8DZfF8s76Ef6qYXeVNXhtjwKfIHBP7+fOTYl05ZHW/OVcI7m\nO/Zuz0lVPVNVv6yqXwH/zOC1AZ2fiySvYRDyn66qz7dqXxdDlnPQr7ifWkjy2iSvP1YGLgUeZjDu\nY3cJbAPubuU9wLXtToOLgReG/jnbi/mO/SvApUnWtKmNS1vdsnfC5y9/yOC1AYNzcU2Ss5KcB2wG\nvkkH76EkAW4FDlTVx4c2+boYttSfBi/kweAT9O8zuHPgo0vdn9Mw3jcxuDPiu8Ajx8YMnAPsAx4H\n/gM4u9WHwX8C8wPgIWByqcewwPF/hsGUxP8wmEPdfipjB/6UwQeS08B1Sz2uMZ6LT7Wx7mcQaOuG\n2n+0nYvHgMuH6pf1ewh4J4Npmf3Ag+1xxUp9Xcz28JuxktS55Tx1I0kagUEvSZ0z6CWpcwa9JHXO\noJekzhn0ktQ5g16SOmfQS1Ln/heLSqNY/f2NTQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNRLjhxP-Ai3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "9a3e9ed6-9607-4723-dbc7-e7e867fc4462"
      },
      "source": [
        "plt.hist([len(d) for d in thurs if len(d)<200], bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDP5oF9D-AeS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "534095e3-46bf-452d-a3a0-5193db964045"
      },
      "source": [
        "len([d for d in thurs if len(d)>75])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoJra3Vad-O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thurs = [d for d in thurs if len(d)>75]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_5mQk_Wd9-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thurs = [' '.join(d.split()) for d in thurs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irGTcbyGd9r_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "4b741474-7f50-44c6-8483-909aba1b25a6"
      },
      "source": [
        "thurs[10]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Nonsense!\" said Gregory, who was very rational when anyone else attempted paradox. \"Why do all the clerks and navvies in the railway trains look so sad and tired, so very sad and tired? I will tell you. It is because they know that the train is going right. It is because they know that whatever place they have taken a ticket for that place they will reach. It is because after they have passed Sloane Square they know that the next station must be Victoria, and nothing but Victoria. Oh, their wild rapture! oh, their eyes like stars and their souls again in Eden, if the next station were unaccountably Baker Street!\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kfc5xpJd9E2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE1-fvAad8sI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ye93C1mdrQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiples(it, n):\n",
        "  for k in range(len(it)-n+1):\n",
        "    yield it[k:k+n]\n",
        "\n",
        "class TopicalLanguageModel:\n",
        "  \"\"\"\n",
        "  Neural Topical Language Model.\n",
        "  \"\"\"\n",
        "  def __init__(self, num_topics, word_embedding, lm_length=30, tokens='abcdefghijklmnopqrstuvwxyz ', batch_size=20):\n",
        "    self.num_topics = num_topics\n",
        "    self.word_embedding = word_embedding\n",
        "    self.lm_length = lm_length\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    token_idx = [(t, k+3) for k,t in enumerate(list(tokens))]\n",
        "    self.token2idx = {t:k for k,t in token_idx}\n",
        "    self.idx2token = {k:t for k,t in token_idx}\n",
        "\n",
        "    self.num_tokens = len(tokens)+3\n",
        "\n",
        "  def generate_train_data(self, documents, batch_size=20): #fix documents inconsistency (list of document strings or list of list of words)\n",
        "    while True:\n",
        "      docs = np.random.choice(documents, size=batch_size)\n",
        "      finish_idxs = [np.random.randint(0, len(d)+1) for d in documents]\n",
        "      \n",
        "      emb = lambda x: self.word_embedding.get(x, np.zeros(self.word_embedding.vector_size))\n",
        "      x_topic = np.array([np.array([emb(w) for w in d]).mean(axis=0) for d in docs])\n",
        "\n",
        "      joined_docs = [' '.join(d) for d in docs]\n",
        "      joined_docs = [d[max(i-self.lm_length,0):i] for i, d in zip(finish_idxs, joined_docs)]\n",
        "      x_lm = np.array([[0]*(self.lm_length - len(d))+[self.token2idx.get(t,2) for t in d] for d in joined_docs])\n",
        "\n",
        "      y = [self.token2idx[d[i]] if i != len(d) else 1 for i,d in zip(start_idxs, joined_docs)]\n",
        "\n",
        "      yield [x_topic, x_lm], y\n",
        "\n",
        "  def fit(self, documents, batch_size=20, epochs=10, verbose=0):\n",
        "    \"\"\"\n",
        "    fit(self, documents)\n",
        "\n",
        "    documents should be a list of sentences, and a sentence a list of words.\n",
        "    \"\"\"\n",
        "    x_topic = Input(shape=(self.word_embedding.vector_size,))\n",
        "    h_topic = Dense(self.word_embedding.vector_size, activation='relu')(x_topic)\n",
        "    out_topic = Dense(self.num_topics, activation='softmax')(h_topic)\n",
        "    self.topic_model = Model(inputs=[x_topic], outputs=out_topic)\n",
        "    \n",
        "    self.language_models = []\n",
        "    for k in range(self.num_topics):\n",
        "      x_lm = Input(shape=(self.lm_length,), dtype='int32')\n",
        "      h_lm = Embedding(input_dim=self.num_tokens, output_dim=self.num_tokens//2, input_length=self.lm_length)(x_lm)\n",
        "      h_lm = LSTM(self.num_tokens)(h_lm)\n",
        "      out_lm = Dense(self.num_tokens, activation='softmax')(h_lm)\n",
        "      lm = Model(inputs=[x_lm], outputs=out_lm)\n",
        "      self.language_models.append(lm)\n",
        "\n",
        "    train_topic_input = Input(shape=(self.word_embedding.vector_size,))\n",
        "    train_lm_input = Input(shape=(self.lm_length,), dtype='int32')\n",
        "\n",
        "    lm_outputs = [Reshape(target_shape=(self.num_tokens, 1))(lm(train_lm_input)) for lm in self.language_models]\n",
        "    lm_outputs = Concatenate(axis=2)(lm_outputs)\n",
        "    topic_mix = self.topic_model(train_topic_input)\n",
        "\n",
        "    out = Dot(axes=(2, 1))([lm_outputs, topic_mix])\n",
        "\n",
        "    self.train_model = Model(inputs=[train_topic_input, train_lm_input], outputs=out)\n",
        "    self.train_model.compile('adam', 'sparse_categorical_crossentropy')\n",
        "\n",
        "    self.train_hist = self.train_model.fit_generator(self.generate_train_data(documents, batch_size=batch_size), \n",
        "                                                     steps_per_epoch=len(documents)//batch_size, \n",
        "                                                     epochs=epochs)\n",
        "\n",
        "  def predict(self, init_doc, topic, method='sample'):\n",
        "    pad_doc = ['<start>']*(self.window-1) + init_doc\n",
        "    key = ' '.join(pad_doc[-self.window+1:])\n",
        "    if method == 'sample':\n",
        "      return np.random.choice([w for w,p in self.ngram_probs[topic][key]],\n",
        "                              p=[p for w,p in self.ngram_probs[topic][key]])\n",
        "    elif method == 'max':\n",
        "      return self.ngram_probs[topic][key][np.argmax([p for w,p in self.ngram_probs[topic][key]])][0]\n",
        "\n",
        "    elif method == 'distribution':\n",
        "      return self.ngram_probs[topic][key]\n",
        "\n",
        "    else:\n",
        "      raise ValueError('Unknown method.')\n",
        "\n",
        "  def rollout(self, init_doc, topic, method='monte-carlo', maxlen=100):\n",
        "    pred_method = 'sample' if method=='monte-carlo' else 'max' if method=='greedy' else ''\n",
        "    \n",
        "    for k in range(maxlen-len(init_doc)):\n",
        "      predicted = self.predict(init_doc, topic, pred_method)\n",
        "      if predicted == '<end>': break\n",
        "      init_doc.append(predicted)\n",
        "\n",
        "    return init_doc\n",
        "\n",
        "  def get_topics(self, doc):\n",
        "    cleaned = self.clean([doc])[0]\n",
        "    bow = self.topic_model.id2word.doc2bow(cleaned)\n",
        "    return [dict(self.topic_model[bow]).get(k,0) for k in range(self.num_topics)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDPnHh3nYEuE",
        "colab_type": "code",
        "outputId": "3dbd1f12-11e1-4fde-f0b4-93a2cc0f1ef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a = [0,1,2,3,4]\n",
        "a[2:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe9T25-V28G-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "a = Input(shape=(2,3))\n",
        "b = Input(shape=(3,))\n",
        "c = Dot(axes=(2,1))([a,b])\n",
        "\n",
        "mdl = Model(inputs=[a, b], outputs=c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXHlHu_m6ilQ",
        "colab_type": "code",
        "outputId": "a6e64527-bbe2-48ab-a5fb-cd84fa98e03e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "a = np.random.randn(1,2,3)\n",
        "b = np.array([[1,1,-1]])\n",
        "a, mdl.predict([a,b])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[-0.70201563, -1.36185487, -1.35750768],\n",
              "         [-1.0031747 , -0.02161372,  0.03331503]]]),\n",
              " array([[-0.7063627, -1.0581034]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG_p8J4O6omM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}