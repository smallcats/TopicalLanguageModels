{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_TLM_v1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smallcats/TopicalLanguageModels/blob/master/Neural_TLM_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFAvBLHfcmrD",
        "colab_type": "code",
        "outputId": "8013e485-5eff-404a-a7f9-705d53acdb17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, Flatten, Lambda, Concatenate, Reshape, Dot\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.15.x`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjRlyo009h4g",
        "colab_type": "code",
        "outputId": "5d2c9789-b714-4179-8326-5d9decde6069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = stopwords.words('english')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-04uRZH79iY5",
        "colab_type": "code",
        "outputId": "81d24943-4029-45cb-f642-eabfc03502df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "thurs = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
        "len(thurs)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "320525"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQN8KBSq-AnY",
        "colab_type": "code",
        "outputId": "2f424f10-c322-4a6c-b101-44f68a27fbeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "thurs = thurs.split('\\n\\n')\n",
        "len(thurs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fa2498a3-f061-431a-93b4-27f874a7a351",
        "id": "TuZus5wfdL35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist([len(d) for d in thurs], bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNRLjhxP-Ai3",
        "colab_type": "code",
        "outputId": "4348258e-ef04-42dc-d1f9-fb52f05eb21a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist([len(d) for d in thurs if len(d)<200], bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPy5lZitkLivvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDP5oF9D-AeS",
        "colab_type": "code",
        "outputId": "43984da4-3e7f-4c2c-f61a-8b1ed8d3c917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len([d for d in thurs if len(d)>75])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoJra3Vad-O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thurs = [d for d in thurs if len(d)>75]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_5mQk_Wd9-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thurs = [' '.join(d.split()) for d in thurs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irGTcbyGd9r_",
        "colab_type": "code",
        "outputId": "e1e375c2-8315-4e10-a90b-4b0199910908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "thurs[10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"Nonsense!\" said Gregory, who was very rational when anyone else attempted paradox. \"Why do all the clerks and navvies in the railway trains look so sad and tired, so very sad and tired? I will tell you. It is because they know that the train is going right. It is because they know that whatever place they have taken a ticket for that place they will reach. It is because after they have passed Sloane Square they know that the next station must be Victoria, and nothing but Victoria. Oh, their wild rapture! oh, their eyes like stars and their souls again in Eden, if the next station were unaccountably Baker Street!\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krbyOqDQbUXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thurs_sent = '\\n'.join(thurs)\n",
        "thurs_sent = nltk.tokenize.sent_tokenize(thurs_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBfZrNBFbO1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doc2words(doc):\n",
        "  words = nltk.tokenize.word_tokenize(doc)\n",
        "  words = [w.lower() for w in words if w.isalpha()]\n",
        "  words = [w for w in words if (len(w)>1) and (w not in stopwords)]\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw7qG968d4Im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thurs_sent = [doc2words(s) for s in thurs_sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI1pCVKGaXdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb = Word2Vec(thurs_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OjwJPY8ahTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "3a17c6ae-5853-4e7d-b56c-064ff40c7b28"
      },
      "source": [
        "emb.wv.similar_by_word('door')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('eyes', 0.9963647127151489),\n",
              " ('street', 0.9962827563285828),\n",
              " ('upon', 0.9962505102157593),\n",
              " ('like', 0.9962358474731445),\n",
              " ('marquis', 0.9962334632873535),\n",
              " ('last', 0.9962024688720703),\n",
              " ('quite', 0.9961917400360107),\n",
              " ('little', 0.9961829781532288),\n",
              " ('whole', 0.9961309432983398),\n",
              " ('went', 0.9961091876029968)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMHtfDD6adq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "we = {w:emb.wv.get_vector(w) for w in emb.wv.vocab}\n",
        "vec_size = emb.vector_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ye93C1mdrQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiples(it, n):\n",
        "  for k in range(len(it)-n+1):\n",
        "    yield it[k:k+n]\n",
        "\n",
        "class TopicalLanguageModel:\n",
        "  \"\"\"\n",
        "  Neural Topical Language Model.\n",
        "\n",
        "  attributes:\n",
        "  num_topics :: int : number of topics\n",
        "  doc2words :: function : takes a document as a string and returns words\n",
        "  word_embedding :: dict : keys are words, values are vectors\n",
        "  vector_size :: int : the dimension of embedding vectors\n",
        "  lm_length :: int : length of tokens taken into account for character-level language models \n",
        "  \"\"\"\n",
        "  def __init__(self, num_topics, word_embedding, vector_size, doc2words, lm_length=30, tokens='abcdefghijklmnopqrstuvwxyz '):\n",
        "    self.num_topics = num_topics\n",
        "    self.doc2words = doc2words\n",
        "    self.word_embedding = word_embedding\n",
        "    self.vector_size = vector_size\n",
        "    self.lm_length = lm_length\n",
        "\n",
        "    self.tokens = ['<', '>', '*'] + list(tokens)\n",
        "    token_idx = [(t, k+3) for k,t in enumerate(list(tokens))] # 0 = start, 1 = end, 2 = unknown\n",
        "    self.token2idx = {t:k for t,k in token_idx}\n",
        "    self.idx2token = {k:t for t,k in token_idx}\n",
        "\n",
        "    self.num_tokens = len(tokens)+3\n",
        "\n",
        "  def generate_train_data(self, documents, batch_size=20): #fix documents inconsistency (list of document strings or list of list of words)\n",
        "    while True:\n",
        "      docs = np.random.choice(documents, size=batch_size)\n",
        "      finish_idxs = [np.random.randint(0, len(d)+1) for d in docs]\n",
        "      \n",
        "      x_topic = np.array([np.array([self.word_embedding[w] for w in self.doc2words(d) if w in self.word_embedding]).mean(axis=0) for d in docs])\n",
        "\n",
        "      lm_docs = [d[max(i-self.lm_length,0):i] for i, d in zip(finish_idxs, docs)]\n",
        "      x_lm = np.array([[0]*(self.lm_length - len(d))+[self.token2idx.get(t,2) for t in d] for d in lm_docs])\n",
        "\n",
        "      y = np.array([self.token2idx.get(d[i],2) if i != len(d) else 1 for i,d in zip(finish_idxs, docs)])\n",
        "      \n",
        "      yield [x_topic, x_lm], y\n",
        "\n",
        "  def fit(self, documents, batch_size=20, epochs=10, verbose=0):\n",
        "    \"\"\"\n",
        "    fit(self, documents)\n",
        "\n",
        "    documents should be a list of sentences, and a sentence a list of words.\n",
        "    \"\"\"\n",
        "    x_topic = Input(shape=(self.vector_size,))\n",
        "    h_topic = Dense(self.vector_size, activation='relu')(x_topic)\n",
        "    out_topic = Dense(self.num_topics, activation='softmax')(h_topic)\n",
        "    self.topic_model = Model(inputs=[x_topic], outputs=out_topic)\n",
        "    \n",
        "    self.language_models = []\n",
        "    for k in range(self.num_topics):\n",
        "      x_lm = Input(shape=(self.lm_length,), dtype='int32')\n",
        "      h_lm = Embedding(input_dim=self.num_tokens, output_dim=self.num_tokens//2, input_length=self.lm_length)(x_lm)\n",
        "      h_lm = LSTM(self.num_tokens)(h_lm)\n",
        "      out_lm = Dense(self.num_tokens, activation='softmax')(h_lm)\n",
        "      lm = Model(inputs=[x_lm], outputs=out_lm)\n",
        "      self.language_models.append(lm)\n",
        "\n",
        "    train_topic_input = Input(shape=(self.vector_size,))\n",
        "    train_lm_input = Input(shape=(self.lm_length,), dtype='int32')\n",
        "\n",
        "    lm_outputs = [Reshape(target_shape=(self.num_tokens, 1))(lm(train_lm_input)) for lm in self.language_models]\n",
        "    lm_outputs = Concatenate(axis=2)(lm_outputs)\n",
        "    topic_mix = self.topic_model(train_topic_input)\n",
        "\n",
        "    out = Dot(axes=(2, 1))([lm_outputs, topic_mix])\n",
        "\n",
        "    self.train_model = Model(inputs=[train_topic_input, train_lm_input], outputs=out)\n",
        "    self.train_model.compile('adam', 'sparse_categorical_crossentropy')\n",
        "\n",
        "    self.train_hist = self.train_model.fit_generator(self.generate_train_data(documents, batch_size=batch_size), \n",
        "                                                     steps_per_epoch=len(documents)//batch_size, \n",
        "                                                     epochs=epochs)\n",
        "\n",
        "  def predict(self, init_doc, topic, method='sample'):\n",
        "    idx_doc = [self.token2idx.get(c,2) for c in init_doc]\n",
        "    dlen = len(idx_doc)\n",
        "    if dlen < self.lm_length:\n",
        "      idx_doc = [0]*(self.lm_length-dlen)+idx_doc\n",
        "    elif dlen > self.lm_length:\n",
        "      idx_doc = idx_doc[-self.lm_length:]\n",
        "\n",
        "    probs = self.language_models[topic].predict(np.array(idx_doc).reshape((1,-1)))[0]\n",
        "\n",
        "    if method == 'sample':\n",
        "      return np.random.choice(self.tokens, p=probs)\n",
        "\n",
        "    elif method == 'max':\n",
        "      return self.tokens[np.argmax(probs)]\n",
        "\n",
        "    elif method == 'distribution':\n",
        "      return probs\n",
        "\n",
        "    else:\n",
        "      raise ValueError('Unknown method.')\n",
        "\n",
        "  def rollout(self, init_doc, topic, method='monte-carlo', maxlen=100):\n",
        "    pred_method = 'sample' if method=='monte-carlo' else 'max' if method=='greedy' else ''\n",
        "    \n",
        "    for k in range(maxlen-len(init_doc)):\n",
        "      predicted = self.predict(init_doc, topic, pred_method)\n",
        "      if predicted == '>': break\n",
        "      init_doc = init_doc + predicted\n",
        "\n",
        "    return init_doc\n",
        "\n",
        "  def get_topics(self, doc):\n",
        "    words = self.doc2words(doc)\n",
        "    embedding = np.array([self.word_embedding[w] for w in words if w in self.word_embedding]).mean(axis=0)\n",
        "    return self.topic_model.predict(embedding.reshape((-1,1)))[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcTAymOvfDSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tlm = TopicalLanguageModel(num_topics=2, word_embedding=emb, vector_size=vec_size, doc2words=doc2words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H65lttW6g8ye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0c6580b6-9e32-4891-a63d-8022a49a853b"
      },
      "source": [
        "tlm.fit(thurs, batch_size=5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "175/175 [==============================] - 9s 52ms/step - loss: 3.0916\n",
            "Epoch 2/10\n",
            "175/175 [==============================] - 7s 40ms/step - loss: 2.8747\n",
            "Epoch 3/10\n",
            "175/175 [==============================] - 7s 41ms/step - loss: 2.8554\n",
            "Epoch 4/10\n",
            "175/175 [==============================] - 7s 41ms/step - loss: 2.8496\n",
            "Epoch 5/10\n",
            "175/175 [==============================] - 7s 42ms/step - loss: 2.8127\n",
            "Epoch 6/10\n",
            "175/175 [==============================] - 7s 41ms/step - loss: 2.6916\n",
            "Epoch 7/10\n",
            "175/175 [==============================] - 7s 41ms/step - loss: 2.6285\n",
            "Epoch 8/10\n",
            "175/175 [==============================] - 7s 42ms/step - loss: 2.6330\n",
            "Epoch 9/10\n",
            "175/175 [==============================] - 7s 41ms/step - loss: 2.5122\n",
            "Epoch 10/10\n",
            "175/175 [==============================] - 7s 40ms/step - loss: 2.5254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG_p8J4O6omM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "947d7f88-4124-4ab5-c762-7f786dcdc081"
      },
      "source": [
        "tlm.predict('m', topic=0)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m59-hFfjlQys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e30d07e9-27d8-44e8-b10f-63f65abffdb7"
      },
      "source": [
        "tlm.rollout('', topic=1, maxlen=100)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cbc t cug ha whte suf n uons nt t te sud ceiwte td pk sg el umsas bt swwe sbd he slu euteasr bor uua'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9prI4MJrTGvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}